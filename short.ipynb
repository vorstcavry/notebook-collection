{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vorstcavry/notebook-collection/blob/https%2Fgithub.com%2Fvorstcavry/short.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZl9FPC9sbW_"
      },
      "source": [
        "# Image Generated Interactive Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8lnApcK4vWv"
      },
      "source": [
        "#Information\n",
        "- Controlnet 1.1 for SD\n",
        "- SDXL models only support txt2img\n",
        "- Lora usually doesn't work correctly alongside Controlnet\n",
        "- More functions, more bugs; less than 10 words, more laughs\n",
        "\n",
        "<small>creator page [Vorst Cavry](https://github.com/vorstcavry) <small/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wILzWiWRfTX8"
      },
      "source": [
        "#**[ID]**\n",
        "Notebook interaktif berbasis widget untuk Google Colab yang memungkinkan pengguna membuat gambar AI dari perintah (Text2Image) menggunakan [Stable Diffusion (by Stability AI, Runway & CompVis)](https://en.wikipedia.org/wiki/Stable_Diffusion).\n",
        "\n",
        "Notebook ini bertujuan untuk menjadi alternatif WebUI sekaligus menawarkan GUI yang sederhana dan ringan bagi siapa saja untuk memulai Difusi Stabil.\n",
        "\n",
        "Menggunakan Difusi Stabil, Diffuser [HuggingFace](https://huggingface.co/) dan [widget Jupyter](https://github.com/jupyter-widgets/ipywidgets).\n",
        "\n",
        "<br/>\n",
        "\n",
        "Notebook Ini Dimodifikasi oleh Remaja Pekalongan\n",
        "\n",
        "Notebook ini referensi milik Redromnon\n",
        "\n",
        "#**[ENG]**\n",
        "A widgets-based interactive notebook for Google Colab that lets users generate AI images from prompts (Text2Image) using [Stable Diffusion (by Stability AI, Runway & CompVis)](https://en.wikipedia.org/wiki/Stable_Diffusion).\n",
        "\n",
        "This notebook aims to be an alternative to WebUIs while offering a simple and lightweight GUI for anyone to get started with Stable Diffusion.\n",
        "\n",
        "Uses Stable Diffusion, [HuggingFace](https://huggingface.co/) Diffusers and [Jupyter widgets](https://github.com/jupyter-widgets/ipywidgets).\n",
        "\n",
        "<br/>\n",
        "\n",
        "This Notebook is Modified by Remaja Pekalongan\n",
        "\n",
        "This notebook is Reromnon's reference\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCR176NNfn0o",
        "outputId": "38230904-c42c-4784-ed1a-d9dd5f02b3c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tunggu Sebentar...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:19<00:00, 19.92s/it]\n"
          ]
        }
      ],
      "source": [
        "#@title ðŸ‘‡ Installing dependencies { display-mode: \"form\" }\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def display_text_box(content, width=\"485px\", height=\"30px\"):\n",
        "    html_content = f'''\n",
        "        <div style=\"\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            justify-content: center;\n",
        "            border: 2px solid #ccc;\n",
        "            background-color: #007bff;\n",
        "            width: {width};\n",
        "            height: {height};\n",
        "            color: white;\n",
        "            font-weight: bold;\n",
        "            text-align: center;\n",
        "        \">{content}</div>\n",
        "    '''\n",
        "    display(HTML(html_content))\n",
        "\n",
        "text_content = \"Terima kasih Telah Menggunakan Notebook google colab StableDiffusion milik Remaja Pekalongan.\"\n",
        "\n",
        "display_text_box(text_content, width=\"485px\", height=\"30px\")\n",
        "\n",
        "from IPython.display import HTML, Image\n",
        "\n",
        "def display_image():\n",
        "    image_url = \"https://i.ibb.co/dtgPhdg/Cuplikan-layar-2023-07-30-165548.png\"\n",
        "    image_html = f'<a href=\"https://www.youtube.com/@remajapekalongan\" target=\"_blank\"><img src=\"{image_url}\" width=\"489\" height=\"172\"></a>'\n",
        "\n",
        "    display(HTML(image_html))\n",
        "\n",
        "display_image()\n",
        "from IPython.display import HTML\n",
        "\n",
        "def create_button_with_link(label, link):\n",
        "    button_id = label.lower().replace(\" \", \"_\")\n",
        "    return f'''\n",
        "        <style>\n",
        "            #{button_id} {{\n",
        "                width: 119px;\n",
        "                height: 40px;\n",
        "                background-color: #007bff;\n",
        "                color: white;\n",
        "                border: 2px solid #ccc;\n",
        "                cursor: pointer;\n",
        "                transition: background-color 0.3s;\n",
        "            }}\n",
        "            #{button_id}:hover {{\n",
        "                background-color: #0056b3;\n",
        "            }}\n",
        "        </style>\n",
        "        <a href=\"{link}\" target=\"_blank\" style=\"text-decoration: none;\">\n",
        "            <button id=\"{button_id}\">{label}</button>\n",
        "        </a>\n",
        "    '''\n",
        "\n",
        "subscribe_button = create_button_with_link(\"Subscribe\", \"https://www.youtube.com/@remajapekalongan\")\n",
        "support_button = create_button_with_link(\"Support\", \"https://ko-fi.com/vorstcavry\")\n",
        "saweria_button = create_button_with_link(\"Saweria\", \"https://http://saweria.co/vorstcavry\")\n",
        "discord_button = create_button_with_link(\"Discord\", \"https://discord.gg/fg9kvMqUmD\")\n",
        "\n",
        "buttons_html = f'<div>{subscribe_button} {support_button} {saweria_button} {discord_button}</div>'\n",
        "display(HTML(buttons_html))\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Pastikan untuk memilih **GPU** sebagai jenis runtime:<br/>\n",
        "#@markdown *Runtime->Ubah Jenis Runtime->Di bawah Akselerator perangkat keras, pilih GPU*\n",
        "#@markdown\n",
        "#@markdown ---\n",
        "#@markdown Make sure to select **GPU** as the runtime type:<br/>\n",
        "#@markdown *Runtime->Change Runtime Type->Under Hardware accelerator, select GPU*\n",
        "#@markdown\n",
        "#@markdown ---\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "packages = [\n",
        "            #\"pip install -q omegaconf==2.3.0 torch git+https://github.com/huggingface/diffusers.git invisible_watermark  transformers accelerate scipy safetensors==0.3.3 xformers mediapy ipywidgets==7.7.1 controlnet_aux==0.0.6 mediapipe==0.10.1\",\n",
        "            #\"pip install -q omegaconf==2.3.0 torch git+https://github.com/huggingface/diffusers.git git+https://github.com/damian0815/compel.git invisible_watermark  transformers accelerate scipy safetensors==0.3.3 xformers safetensors mediapy ipywidgets==7.7.1 controlnet_aux==0.0.6 mediapipe==0.10.1\",\n",
        "            #\"pip install -q omegaconf==2.3.0 torch git+https://github.com/huggingface/diffusers.git git+https://github.com/damian0815/compel.git invisible_watermark  transformers accelerate scipy safetensors==0.3.3 xformers safetensors mediapy ipywidgets==7.7.1 controlnet_aux==0.0.6 mediapipe==0.10.1 pytorch-lightning asdff\",\n",
        "            \"pip install -q omegaconf==2.3.0 torch git+https://github.com/huggingface/diffusers.git git+https://github.com/damian0815/compel.git invisible_watermark  transformers accelerate scipy safetensors==0.3.3 xformers safetensors mediapy ipywidgets==7.7.1 controlnet_aux==0.0.6 mediapipe==0.10.1 pytorch-lightning asdff\",\n",
        "            \"apt install git-lfs\",\n",
        "            \"git lfs install\",\n",
        "            \"apt -y install -qq aria2\"\n",
        "            ]\n",
        "\n",
        "for install in tqdm(packages, desc=print(\"Tunggu Sebentar...\")):\n",
        "    os.system(install)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ‘‡ Download Model: Please provide a link for the Civitai API, Google Drive, or Hugging Face. { form-width: \"20%\", display-mode: \"form\" }\n",
        "import os\n",
        "%cd /content\n",
        "\n",
        "def download_things(directory, url, hf_token=\"\"):\n",
        "    url = url.strip()\n",
        "\n",
        "    if \"drive.google.com\" in url:\n",
        "        original_dir = os.getcwd()\n",
        "        os.chdir(directory)\n",
        "        !gdown --fuzzy {url}\n",
        "        os.chdir(original_dir)\n",
        "    elif \"huggingface.co\" in url:\n",
        "        if \"/blob/\" in url:\n",
        "            url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "        user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 {url} -d {directory}  -o {url.split('/')[-1]}\n",
        "    else:\n",
        "        !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {directory} {url}\n",
        "\n",
        "def get_model_list(directory_path):\n",
        "    model_list = []\n",
        "    valid_extensions = {'.ckpt' , '.pt', '.pth', '.safetensors', '.bin'}\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if os.path.splitext(filename)[1] in valid_extensions:\n",
        "            name_without_extension = os.path.splitext(filename)[0]\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            model_list.append((name_without_extension, file_path))\n",
        "            print('\\033[34mFILE: ' + name_without_extension + file_path + '\\033[0m')\n",
        "    return model_list\n",
        "\n",
        "def process_string(input_string):\n",
        "    parts = input_string.split('/')\n",
        "\n",
        "    if len(parts) == 2:\n",
        "        first_element = parts[1]\n",
        "        complete_string = input_string\n",
        "        result = (first_element, complete_string)\n",
        "        return result\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "directory_models = 'models'\n",
        "os.makedirs(directory_models, exist_ok=True)\n",
        "directory_loras = 'loras'\n",
        "os.makedirs(directory_loras, exist_ok=True)\n",
        "directory_vaes = 'vaes'\n",
        "os.makedirs(directory_vaes, exist_ok=True)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown - **Download a Model**\n",
        "download_model = \"https://huggingface.co/NoCrypt/SomethingV2_2/resolve/main/SomethingV2_2.safetensors\" # @param {type:\"string\"}\n",
        "#@markdown - For SDXL models, only diffuser format models are supported, and you only need the repository name.\n",
        "load_diffusers_format_model = 'Linaqruf/animagine-xl' # @param {type:\"string\"}\n",
        "#@markdown - **Download a VAE**\n",
        "download_vae = \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\" # @param {type:\"string\"}\n",
        "#@markdown - **Download a LoRA**\n",
        "download_lora = \"https://huggingface.co/vorstcavry/mymodel1/resolve/main/GoodHands-beta2.safetensors\" # @param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **HF TOKEN** - If you need to download your private model from Hugging Face, input your token here.\n",
        "hf_token = \"\"  # @param {type:\"string\"}\n",
        "#@markdown\n",
        "#@markdown ---\n",
        "\n",
        "download_things(directory_models, download_model, hf_token)\n",
        "download_things(directory_vaes, download_vae, hf_token)\n",
        "download_things(directory_loras, download_lora, hf_token)\n",
        "\n",
        "\n",
        "# TI more combatible in safetensor format; maybe convert to safetensor can help\n",
        "packages = [\n",
        "            \"git clone https://github.com/vorstcavry/embeddings /content/embedings\"\n",
        "            ]\n",
        "\n",
        "for install in tqdm(packages, desc=print(\"Tunggu Sebentar...\")):\n",
        "    os.system(install)\n",
        "\n",
        "\n",
        "print('\\033[33m [âœ”] Files successfully installed.\\033[0m')\n",
        "directory_embeds = 'embedings'\n",
        "embed_list = get_model_list(directory_embeds)\n",
        "\n",
        "model_list = get_model_list(directory_models)\n",
        "if load_diffusers_format_model.strip() != \"\" and load_diffusers_format_model.count('/') == 1:\n",
        "    model_list.append(process_string(load_diffusers_format_model))\n",
        "lora_model_list = get_model_list(directory_loras)\n",
        "lora_model_list.insert(0, (\"None\",\"None\"))\n",
        "vae_model_list = get_model_list(directory_vaes)\n",
        "vae_model_list.insert(0, (\"None\",\"None\"))\n",
        "\n",
        "\n",
        "\n",
        "print('\\033[33mðŸ Download finished.\\033[0m')\n",
        "\n",
        "### SECOND PART ###\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import gc\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from diffusers import (ControlNetModel, DiffusionPipeline,\n",
        "                       StableDiffusionControlNetPipeline,\n",
        "                       UniPCMultistepScheduler)\n",
        "import gc\n",
        "import torch\n",
        "from controlnet_aux import (CannyDetector, ContentShuffleDetector, HEDdetector,\n",
        "                            LineartAnimeDetector, LineartDetector,\n",
        "                            MidasDetector, MLSDdetector, NormalBaeDetector,\n",
        "                            OpenposeDetector, PidiNetDetector)\n",
        "from transformers import pipeline\n",
        "from controlnet_aux.util import HWC3, ade_palette\n",
        "from transformers import AutoImageProcessor, UperNetForSemanticSegmentation\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "### UTILS ###\n",
        "def resize_image(input_image, resolution, interpolation=None):\n",
        "    H, W, C = input_image.shape\n",
        "    H = float(H)\n",
        "    W = float(W)\n",
        "    k = float(resolution) / max(H, W)\n",
        "    H *= k\n",
        "    W *= k\n",
        "    H = int(np.round(H / 64.0)) * 64\n",
        "    W = int(np.round(W / 64.0)) * 64\n",
        "    if interpolation is None:\n",
        "        interpolation = cv2.INTER_LANCZOS4 if k > 1 else cv2.INTER_AREA\n",
        "    img = cv2.resize(input_image, (W, H), interpolation=interpolation)\n",
        "    return img\n",
        "\n",
        "class DepthEstimator:\n",
        "    def __init__(self):\n",
        "        self.model = pipeline('depth-estimation')\n",
        "\n",
        "    def __call__(self, image: np.ndarray, **kwargs) -> PIL.Image.Image:\n",
        "        detect_resolution = kwargs.pop('detect_resolution', 512)\n",
        "        image_resolution = kwargs.pop('image_resolution', 512)\n",
        "        image = np.array(image)\n",
        "        image = HWC3(image)\n",
        "        image = resize_image(image, resolution=detect_resolution)\n",
        "        image = PIL.Image.fromarray(image)\n",
        "        image = self.model(image)\n",
        "        image = image['depth']\n",
        "        image = np.array(image)\n",
        "        image = HWC3(image)\n",
        "        image = resize_image(image, resolution=image_resolution)\n",
        "        return PIL.Image.fromarray(image)\n",
        "\n",
        "class ImageSegmentor:\n",
        "    def __init__(self):\n",
        "        self.image_processor = AutoImageProcessor.from_pretrained(\n",
        "            'openmmlab/upernet-convnext-small')\n",
        "        self.image_segmentor = UperNetForSemanticSegmentation.from_pretrained(\n",
        "            'openmmlab/upernet-convnext-small')\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def __call__(self, image: np.ndarray, **kwargs) -> PIL.Image.Image:\n",
        "        detect_resolution = kwargs.pop('detect_resolution', 512)\n",
        "        image_resolution = kwargs.pop('image_resolution', 512)\n",
        "        image = HWC3(image)\n",
        "        image = resize_image(image, resolution=detect_resolution)\n",
        "        image = PIL.Image.fromarray(image)\n",
        "\n",
        "        pixel_values = self.image_processor(image,\n",
        "                                            return_tensors='pt').pixel_values\n",
        "        outputs = self.image_segmentor(pixel_values)\n",
        "        seg = self.image_processor.post_process_semantic_segmentation(\n",
        "            outputs, target_sizes=[image.size[::-1]])[0]\n",
        "        color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)\n",
        "        for label, color in enumerate(ade_palette()):\n",
        "            color_seg[seg == label, :] = color\n",
        "        color_seg = color_seg.astype(np.uint8)\n",
        "\n",
        "        color_seg = resize_image(color_seg,\n",
        "                                 resolution=image_resolution,\n",
        "                                 interpolation=cv2.INTER_NEAREST)\n",
        "        return PIL.Image.fromarray(color_seg)\n",
        "\n",
        "class Preprocessor:\n",
        "    MODEL_ID = 'lllyasviel/Annotators'\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.name = ''\n",
        "\n",
        "    def load(self, name: str) -> None:\n",
        "        if name == self.name:\n",
        "            return\n",
        "        if name == 'HED':\n",
        "            self.model = HEDdetector.from_pretrained(self.MODEL_ID)\n",
        "        elif name == 'Midas':\n",
        "            self.model = MidasDetector.from_pretrained(self.MODEL_ID)\n",
        "        elif name == 'MLSD':\n",
        "            self.model = MLSDdetector.from_pretrained(self.MODEL_ID)\n",
        "        elif name == 'Openpose':\n",
        "            self.model = OpenposeDetector.from_pretrained(self.MODEL_ID)\n",
        "        elif name == 'PidiNet':\n",
        "            self.model = PidiNetDetector.from_pretrained(self.MODEL_ID)\n",
        "        elif name == 'NormalBae':\n",
        "            self.model = NormalBaeDetector.from_pretrained(self.MODEL_ID)\n",
        "        elif name == 'Lineart':\n",
        "            self.model = LineartDetector.from_pretrained(self.MODEL_ID)\n",
        "        elif name == 'LineartAnime':\n",
        "            self.model = LineartAnimeDetector.from_pretrained(self.MODEL_ID)\n",
        "        elif name == 'Canny':\n",
        "            self.model = CannyDetector()\n",
        "        elif name == 'ContentShuffle':\n",
        "            self.model = ContentShuffleDetector()\n",
        "        elif name == 'DPT':\n",
        "            self.model = DepthEstimator()\n",
        "        elif name == 'UPerNet':\n",
        "            self.model = ImageSegmentor()\n",
        "        else:\n",
        "            raise ValueError\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, image: PIL.Image.Image, **kwargs) -> PIL.Image.Image:\n",
        "        if self.name == 'Canny':\n",
        "            if 'detect_resolution' in kwargs:\n",
        "                detect_resolution = kwargs.pop('detect_resolution')\n",
        "                image = np.array(image)\n",
        "                image = HWC3(image)\n",
        "                image = resize_image(image, resolution=detect_resolution)\n",
        "            image = self.model(image, **kwargs)\n",
        "            return PIL.Image.fromarray(image)\n",
        "        elif self.name == 'Midas':\n",
        "            detect_resolution = kwargs.pop('detect_resolution', 512)\n",
        "            image_resolution = kwargs.pop('image_resolution', 512)\n",
        "            image = np.array(image)\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=detect_resolution)\n",
        "            image = self.model(image, **kwargs)\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=image_resolution)\n",
        "            return PIL.Image.fromarray(image)\n",
        "        else:\n",
        "            return self.model(image, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "### CONTROLNET MODEL CLASS ###\n",
        "MAX_IMAGE_RESOLUTION = 4096 ## â­\n",
        "MAX_NUM_IMAGES = 16 ## â­\n",
        "\n",
        "CONTROLNET_MODEL_IDS = {\n",
        "    'Openpose': 'lllyasviel/control_v11p_sd15_openpose',\n",
        "    'Canny': 'lllyasviel/control_v11p_sd15_canny',\n",
        "    'MLSD': 'lllyasviel/control_v11p_sd15_mlsd',\n",
        "    'scribble': 'lllyasviel/control_v11p_sd15_scribble',\n",
        "    'softedge': 'lllyasviel/control_v11p_sd15_softedge',\n",
        "    'segmentation': 'lllyasviel/control_v11p_sd15_seg',\n",
        "    'depth': 'lllyasviel/control_v11f1p_sd15_depth',\n",
        "    'NormalBae': 'lllyasviel/control_v11p_sd15_normalbae',\n",
        "    'lineart': 'lllyasviel/control_v11p_sd15_lineart',\n",
        "    'lineart_anime': 'lllyasviel/control_v11p_sd15s2_lineart_anime',\n",
        "    'shuffle': 'lllyasviel/control_v11e_sd15_shuffle',\n",
        "    'ip2p': 'lllyasviel/control_v11e_sd15_ip2p',\n",
        "    'inpaint': 'lllyasviel/control_v11e_sd15_inpaint',\n",
        "    'txt2img': 'NotControlnet',\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def download_all_controlnet_weights() -> None:\n",
        "    for model_id in CONTROLNET_MODEL_IDS.values():\n",
        "        ControlNetModel.from_pretrained(model_id)\n",
        "\n",
        "from diffusers import AutoencoderKL\n",
        "class Model:\n",
        "    def __init__(self,\n",
        "                 base_model_id: str = 'runwayml/stable-diffusion-v1-5',\n",
        "                 task_name: str = 'Canny', vae_model=None):\n",
        "        self.device = torch.device(\n",
        "            'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        self.base_model_id = ''\n",
        "        self.task_name = ''\n",
        "        self.vae_model = None\n",
        "        self.pipe = self.load_pipe(base_model_id, task_name, vae_model)\n",
        "        self.preprocessor = Preprocessor()\n",
        "\n",
        "\n",
        "    def load_pipe(self, base_model_id: str, task_name, vae_model=None, reload=False) -> DiffusionPipeline:\n",
        "        if base_model_id == self.base_model_id and task_name == self.task_name and hasattr(\n",
        "                self, 'pipe') and self.vae_model==vae_model and self.pipe is not None and reload==False:\n",
        "            print('previous loaded')\n",
        "            return self.pipe\n",
        "\n",
        "        self.pipe = None\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        model_id = CONTROLNET_MODEL_IDS[task_name]\n",
        "\n",
        "        if task_name == 'txt2img':\n",
        "            if os.path.exists(base_model_id):\n",
        "                pipe = StableDiffusionPipeline.from_single_file(\n",
        "                  base_model_id,\n",
        "                  vae = None if vae_model == 'None' else AutoencoderKL.from_single_file(vae_model), # , torch_dtype=torch.float16\n",
        "                  torch_dtype=torch.float16,\n",
        "                ).to(\"cuda\")\n",
        "                pipe.safety_checker = None\n",
        "            else:\n",
        "                pipe = DiffusionPipeline.from_pretrained(\n",
        "                    base_model_id,\n",
        "                    vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16),\n",
        "                    torch_dtype=torch.float16,\n",
        "                    use_safetensors=True,\n",
        "                    variant=\"fp16\",\n",
        "                    ).to(\"cuda\")\n",
        "                pipe.safety_checker = None\n",
        "            print('loaded txt2img pipeline')\n",
        "        else:\n",
        "            controlnet = ControlNetModel.from_pretrained(model_id,\n",
        "                                                        torch_dtype=torch.float16)\n",
        "            if os.path.exists(base_model_id):\n",
        "                pipe = StableDiffusionControlNetPipeline.from_single_file(\n",
        "                    base_model_id,\n",
        "                    vae = None if vae_model == 'None' else AutoencoderKL.from_single_file(vae_model),\n",
        "                    safety_checker=None,\n",
        "                    controlnet=controlnet,\n",
        "                    torch_dtype=torch.float16)\n",
        "            else:\n",
        "                pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "                    base_model_id,\n",
        "                    vae = AutoencoderKL.from_pretrained(base_model_id, subfolder='vae') if vae_model == 'None' else AutoencoderKL.from_single_file(vae_model),\n",
        "                    safety_checker=None,\n",
        "                    controlnet=controlnet,\n",
        "                    torch_dtype=torch.float16)\n",
        "            print('Loaded ControlNet pipeline')\n",
        "\n",
        "            pipe.scheduler = UniPCMultistepScheduler.from_config(\n",
        "                pipe.scheduler.config)\n",
        "\n",
        "        if self.device.type == 'cuda':\n",
        "            pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "        pipe.to(self.device)\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        self.pipe = pipe\n",
        "        self.base_model_id = base_model_id\n",
        "        self.task_name = task_name\n",
        "        self.vae_model = vae_model\n",
        "        return pipe\n",
        "\n",
        "    def set_base_model(self, base_model_id: str) -> str:\n",
        "        if not base_model_id or base_model_id == self.base_model_id:\n",
        "            return self.base_model_id\n",
        "        del self.pipe\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        try:\n",
        "            self.pipe = self.load_pipe(base_model_id, self.task_name, self.vae_model)\n",
        "        except Exception:\n",
        "            self.pipe = self.load_pipe(self.base_model_id, self.task_name, self.vae_model)\n",
        "        return self.base_model_id\n",
        "\n",
        "    def load_controlnet_weight(self, task_name: str) -> None:\n",
        "        if task_name == self.task_name:\n",
        "            return\n",
        "        if self.pipe is not None and hasattr(self.pipe, 'controlnet'):\n",
        "            del self.pipe.controlnet\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        model_id = CONTROLNET_MODEL_IDS[task_name]\n",
        "        controlnet = ControlNetModel.from_pretrained(model_id,\n",
        "                                                     torch_dtype=torch.float16)\n",
        "        controlnet.to(self.device)\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        self.pipe.controlnet = controlnet\n",
        "        self.task_name = task_name\n",
        "\n",
        "    def get_prompt(self, prompt: str, additional_prompt: str) -> str:\n",
        "        if not prompt:\n",
        "            prompt = additional_prompt\n",
        "        else:\n",
        "            prompt = f'{prompt}, {additional_prompt}'\n",
        "        return prompt\n",
        "\n",
        "    @torch.autocast('cuda')\n",
        "    def run_pipe(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        negative_prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        control_image: PIL.Image.Image,\n",
        "        num_images: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        generator = torch.Generator().manual_seed(seed)\n",
        "        return self.pipe(\n",
        "            # prompt=prompt,\n",
        "            # negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            guidance_scale=guidance_scale,\n",
        "            num_images_per_prompt=num_images,\n",
        "            num_inference_steps=num_steps,\n",
        "            generator=generator,\n",
        "            image=control_image).images\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_canny(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str = \"best quality, extremely detailed\",\n",
        "        negative_prompt: str = \"\",\n",
        "        num_images: int = 1,\n",
        "        image_resolution: int = 512,\n",
        "        num_steps: int = 30,\n",
        "        guidance_scale: float = 7.5,\n",
        "        seed: int = -1,\n",
        "        low_threshold: int = 100,\n",
        "        high_threshold: int = 200,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        self.preprocessor.load('Canny')\n",
        "        control_image = self.preprocessor(image=image,\n",
        "                                          low_threshold=low_threshold,\n",
        "                                          high_threshold=high_threshold,\n",
        "                                          detect_resolution=image_resolution)\n",
        "\n",
        "        self.load_controlnet_weight('Canny')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_mlsd(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        preprocess_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "        value_threshold: float,\n",
        "        distance_threshold: float,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        self.preprocessor.load('MLSD')\n",
        "        control_image = self.preprocessor(\n",
        "            image=image,\n",
        "            image_resolution=image_resolution,\n",
        "            detect_resolution=preprocess_resolution,\n",
        "            thr_v=value_threshold,\n",
        "            thr_d=distance_threshold,\n",
        "        )\n",
        "        self.load_controlnet_weight('MLSD')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_scribble(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        preprocess_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "        preprocessor_name: str,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        if preprocessor_name == 'None':\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=image_resolution)\n",
        "            control_image = PIL.Image.fromarray(image)\n",
        "        elif preprocessor_name == 'HED':\n",
        "            self.preprocessor.load(preprocessor_name)\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "                scribble=False,\n",
        "            )\n",
        "        elif preprocessor_name == 'PidiNet':\n",
        "            self.preprocessor.load(preprocessor_name)\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "                safe=False,\n",
        "            )\n",
        "        self.load_controlnet_weight('scribble')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_scribble_interactive(\n",
        "        self,\n",
        "        image_and_mask: dict[str, np.ndarray],\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image_and_mask is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        image = image_and_mask['mask']\n",
        "        image = HWC3(image)\n",
        "        image = resize_image(image, resolution=image_resolution)\n",
        "        control_image = PIL.Image.fromarray(image)\n",
        "\n",
        "        self.load_controlnet_weight('scribble')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_softedge(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        preprocess_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "        preprocessor_name: str,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        if preprocessor_name == 'None':\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=image_resolution)\n",
        "            control_image = PIL.Image.fromarray(image)\n",
        "        elif preprocessor_name in ['HED', 'HED safe']:\n",
        "            safe = 'safe' in preprocessor_name\n",
        "            self.preprocessor.load('HED')\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "                scribble=safe,\n",
        "            )\n",
        "        elif preprocessor_name in ['PidiNet', 'PidiNet safe']:\n",
        "            safe = 'safe' in preprocessor_name\n",
        "            self.preprocessor.load('PidiNet')\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "                safe=safe,\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError\n",
        "        self.load_controlnet_weight('softedge')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_openpose(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        preprocess_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "        preprocessor_name: str,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        if preprocessor_name == 'None':\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=image_resolution)\n",
        "            control_image = PIL.Image.fromarray(image)\n",
        "        else:\n",
        "            self.preprocessor.load('Openpose')\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "                hand_and_face=True,\n",
        "            )\n",
        "        self.load_controlnet_weight('Openpose')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_segmentation(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        preprocess_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "        preprocessor_name: str,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        if preprocessor_name == 'None':\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=image_resolution)\n",
        "            control_image = PIL.Image.fromarray(image)\n",
        "        else:\n",
        "            self.preprocessor.load(preprocessor_name)\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "            )\n",
        "        self.load_controlnet_weight('segmentation')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_depth(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        preprocess_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "        preprocessor_name: str,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        if preprocessor_name == 'None':\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=image_resolution)\n",
        "            control_image = PIL.Image.fromarray(image)\n",
        "        else:\n",
        "            self.preprocessor.load(preprocessor_name)\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "            )\n",
        "        self.load_controlnet_weight('depth')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_normal(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        preprocess_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "        preprocessor_name: str,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        if preprocessor_name == 'None':\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=image_resolution)\n",
        "            control_image = PIL.Image.fromarray(image)\n",
        "        else:\n",
        "            self.preprocessor.load('NormalBae')\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "            )\n",
        "        self.load_controlnet_weight('NormalBae')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_lineart(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        preprocess_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "        preprocessor_name: str,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        if preprocessor_name in ['None', 'None (anime)']:\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=image_resolution)\n",
        "            control_image = PIL.Image.fromarray(image)\n",
        "        elif preprocessor_name in ['Lineart', 'Lineart coarse']:\n",
        "            coarse = 'coarse' in preprocessor_name\n",
        "            self.preprocessor.load('Lineart')\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "                coarse=coarse,\n",
        "            )\n",
        "        elif preprocessor_name == 'Lineart (anime)':\n",
        "            self.preprocessor.load('LineartAnime')\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "                detect_resolution=preprocess_resolution,\n",
        "            )\n",
        "        if 'anime' in preprocessor_name:\n",
        "            self.load_controlnet_weight('lineart_anime')\n",
        "        else:\n",
        "            self.load_controlnet_weight('lineart')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_shuffle(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "        preprocessor_name: str,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        if preprocessor_name == 'None':\n",
        "            image = HWC3(image)\n",
        "            image = resize_image(image, resolution=image_resolution)\n",
        "            control_image = PIL.Image.fromarray(image)\n",
        "        else:\n",
        "            self.preprocessor.load(preprocessor_name)\n",
        "            control_image = self.preprocessor(\n",
        "                image=image,\n",
        "                image_resolution=image_resolution,\n",
        "            )\n",
        "        self.load_controlnet_weight('shuffle')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def process_ip2p(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        prompt: str,\n",
        "        prompt_embeds,\n",
        "        negative_prompt_embeds,\n",
        "        additional_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        num_images: int,\n",
        "        image_resolution: int,\n",
        "        num_steps: int,\n",
        "        guidance_scale: float,\n",
        "        seed: int,\n",
        "    ) -> list[PIL.Image.Image]:\n",
        "        if image is None:\n",
        "            raise ValueError\n",
        "        if image_resolution > MAX_IMAGE_RESOLUTION:\n",
        "            raise ValueError\n",
        "        if num_images > MAX_NUM_IMAGES:\n",
        "            raise ValueError\n",
        "\n",
        "        image = HWC3(image)\n",
        "        image = resize_image(image, resolution=image_resolution)\n",
        "        control_image = PIL.Image.fromarray(image)\n",
        "        self.load_controlnet_weight('ip2p')\n",
        "        results = self.run_pipe(\n",
        "            prompt=self.get_prompt(prompt, additional_prompt),\n",
        "            negative_prompt=negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            control_image=control_image,\n",
        "            num_images=num_images,\n",
        "            num_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            seed=seed,\n",
        "        )\n",
        "        return [control_image] + results\n",
        "\n",
        "### 3 ####\n",
        "# Prompt weights\n",
        "from compel import Compel\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "import re\n",
        "\n",
        "\n",
        "def concat_tensor(t):\n",
        "    t_list = torch.split(t, 1, dim=0)\n",
        "    t = torch.cat(t_list, dim=1)\n",
        "    return t\n",
        "\n",
        "def merge_embeds(prompt_chanks):\n",
        "    num_chanks = len(prompt_chanks)\n",
        "    power_prompt = 1/(num_chanks*(num_chanks+1)//2)\n",
        "    prompt_embs = compel(prompt_chanks)\n",
        "    t_list = list(torch.split(prompt_embs, 1, dim=0))\n",
        "    for i in range(num_chanks):\n",
        "        t_list[-(i+1)] = t_list[-(i+1)] * ((i+1)*power_prompt)\n",
        "    prompt_emb = torch.stack(t_list, dim=0).sum(dim=0)\n",
        "    return prompt_emb\n",
        "\n",
        "def detokenize(chunk, actual_prompt):\n",
        "    chunk[-1] = chunk[-1].replace('</w>', '')\n",
        "    chanked_prompt = ''.join(chunk).strip()\n",
        "    while '</w>' in chanked_prompt:\n",
        "        if actual_prompt[chanked_prompt.find('</w>')] == ' ':\n",
        "            chanked_prompt = chanked_prompt.replace('</w>', ' ', 1)\n",
        "        else:\n",
        "            chanked_prompt = chanked_prompt.replace('</w>', '', 1)\n",
        "    actual_prompt = actual_prompt.replace(chanked_prompt,'')\n",
        "    return chanked_prompt.strip(), actual_prompt.strip()\n",
        "\n",
        "def tokenize_line(line, tokenizer): # split into chunks\n",
        "    actual_prompt = line.lower().strip()\n",
        "    if actual_prompt == \"\":\n",
        "      actual_prompt = 'worst quality'\n",
        "    actual_tokens = tokenizer.tokenize(actual_prompt)\n",
        "    max_tokens = tokenizer.model_max_length - 2\n",
        "    comma_token = tokenizer.tokenize(',')[0]\n",
        "\n",
        "    chunks = []\n",
        "    chunk = []\n",
        "    for item in actual_tokens:\n",
        "        chunk.append(item)\n",
        "        if len(chunk) == max_tokens:\n",
        "            if chunk[-1] != comma_token:\n",
        "                for i in range(max_tokens-1, -1, -1):\n",
        "                    if chunk[i] == comma_token:\n",
        "                        actual_chunk, actual_prompt = detokenize(chunk[:i+1], actual_prompt)\n",
        "                        chunks.append(actual_chunk)\n",
        "                        chunk = chunk[i+1:]\n",
        "                        break\n",
        "                else:\n",
        "                    actual_chunk, actual_prompt = detokenize(chunk, actual_prompt)\n",
        "                    chunks.append(actual_chunk)\n",
        "                    chunk = []\n",
        "            else:\n",
        "                actual_chunk, actual_prompt = detokenize(chunk, actual_prompt)\n",
        "                chunks.append(actual_chunk)\n",
        "                chunk = []\n",
        "    if chunk:\n",
        "        actual_chunk, _ = detokenize(chunk, actual_prompt)\n",
        "        chunks.append(actual_chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def prompt_weight_conversor(input_string):\n",
        "    # Convert prompt weights from a1... to comel\n",
        "\n",
        "    # Find and replace instances of the colon format with the desired format\n",
        "    converted_string = re.sub(r'\\(([^:]+):([\\d.]+)\\)', r'(\\1)\\2', input_string)\n",
        "\n",
        "    # Find and replace square brackets with round brackets and assign weight\n",
        "    converted_string = re.sub(r'\\[([^:\\]]+)\\]', r'(\\1)0.909090909', converted_string)\n",
        "\n",
        "    # Handle the general case of [x:number] and convert it to (x)0.9\n",
        "    converted_string = re.sub(r'\\[([^:]+):[\\d.]+\\]', r'(\\1)0.9', converted_string)\n",
        "\n",
        "    # Add a '+' sign after the closing parenthesis if no weight is specified\n",
        "    converted_string = re.sub(r'\\(([^)]+)\\)(?![\\d.])', r'(\\1)+', converted_string)\n",
        "\n",
        "    # double (())\n",
        "    modified_string = re.sub(r'\\(\\(([^)]+)\\)\\+\\)', r'(\\1)++', converted_string)\n",
        "\n",
        "    # triple ((()))\n",
        "    #modified_string = re.sub(r'\\(\\(([^)]+)\\)\\+\\+\\)', r'(\\1)+++', modified_string)\n",
        "\n",
        "    #print(modified_string)\n",
        "    return modified_string\n",
        "\n",
        "\n",
        "# IMAGE: METADATA AND SAVE\n",
        "import os\n",
        "from PIL import Image\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "def save_pil_image_with_metadata(image, folder_path, metadata_list):\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    existing_files = os.listdir(folder_path)\n",
        "\n",
        "    # Determine the next available image name\n",
        "    image_name = f\"image{str(len(existing_files) + 1).zfill(3)}.png\"\n",
        "    image_path = os.path.join(folder_path, image_name)\n",
        "\n",
        "    try:\n",
        "        # metadata\n",
        "        metadata = PngInfo()\n",
        "        metadata.add_text(\"Prompt\", str(metadata_list[0]))\n",
        "        metadata.add_text(\"Negative prompt\", str(metadata_list[1]))\n",
        "        metadata.add_text(\"Model\", str(metadata_list[2]))\n",
        "        metadata.add_text(\"VAE\", str(metadata_list[3]))\n",
        "        metadata.add_text(\"Steps\", str(metadata_list[4]))\n",
        "        metadata.add_text(\"CFG\", str(metadata_list[5]))\n",
        "        metadata.add_text(\"Scheduler\", str(metadata_list[6]))\n",
        "        metadata.add_text(\"Seed\", str(metadata_list[7]))\n",
        "\n",
        "        image.save(image_path, pnginfo=metadata)\n",
        "    except:\n",
        "        print('Saving image without metadata')\n",
        "        image.save(image_path)\n",
        "\n",
        "    return image_path"
      ],
      "metadata": {
        "id": "qTbH6SoiRR_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc95515c-55e4-4b15-b9bb-c6f81d8735ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "20f262|\u001b[1;32mOK\u001b[0m  |       0B/s|models/SomethingV2_2.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "19c60e|\u001b[1;32mOK\u001b[0m  |       0B/s|vaes/vae-ft-mse-840000-ema-pruned.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "1f2455|\u001b[1;32mOK\u001b[0m  |       0B/s|loras/GoodHands-beta2.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "Tunggu Sebentar...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 138.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m[âœ”] Files successfully installed.\u001b[0m\n",
            "\u001b[34mFILE: negative_promptembedings/negative_prompt.pt\u001b[0m\n",
            "\u001b[34mFILE: bad-image-v2-39000embedings/bad-image-v2-39000.pt\u001b[0m\n",
            "\u001b[34mFILE: bad_picturesembedings/bad_pictures.pt\u001b[0m\n",
            "\u001b[34mFILE: badhandv4embedings/badhandv4.pt\u001b[0m\n",
            "\u001b[34mFILE: bad-artist-animeembedings/bad-artist-anime.pt\u001b[0m\n",
            "\u001b[34mFILE: BadNegAnatomyV1-negembedings/BadNegAnatomyV1-neg.pt\u001b[0m\n",
            "\u001b[34mFILE: bad-hands-5embedings/bad-hands-5.pt\u001b[0m\n",
            "\u001b[34mFILE: EasyNegativeV2embedings/EasyNegativeV2.safetensors\u001b[0m\n",
            "\u001b[34mFILE: 16-token-negative-deliberate-negembedings/16-token-negative-deliberate-neg.pt\u001b[0m\n",
            "\u001b[34mFILE: BadDreamembedings/BadDream.pt\u001b[0m\n",
            "\u001b[34mFILE: FastNegativeEmbeddingembedings/FastNegativeEmbedding.pt\u001b[0m\n",
            "\u001b[34mFILE: DrD_PNTE768embedings/DrD_PNTE768.pt\u001b[0m\n",
            "\u001b[34mFILE: negmutation-2400embedings/negmutation-2400.pt\u001b[0m\n",
            "\u001b[34mFILE: neg_Colorizer768-neutralembedings/neg_Colorizer768-neutral.pt\u001b[0m\n",
            "\u001b[34mFILE: badqualityembedings/badquality.pt\u001b[0m\n",
            "\u001b[34mFILE: bad_prompt_version2-negembedings/bad_prompt_version2-neg.pt\u001b[0m\n",
            "\u001b[34mFILE: bad_prompt_version2embedings/bad_prompt_version2.pt\u001b[0m\n",
            "\u001b[34mFILE: bad-artistembedings/bad-artist.pt\u001b[0m\n",
            "\u001b[34mFILE: 7dirtywordsembedings/7dirtywords.pt\u001b[0m\n",
            "\u001b[34mFILE: negative_hand-negembedings/negative_hand-neg.pt\u001b[0m\n",
            "\u001b[34mFILE: kkw-Extreme-Negembedings/kkw-Extreme-Neg.pt\u001b[0m\n",
            "\u001b[34mFILE: verybadimagenegative_v1.3embedings/verybadimagenegative_v1.3.pt\u001b[0m\n",
            "\u001b[34mFILE: ng_deepnegative_v1_75tembedings/ng_deepnegative_v1_75t.pt\u001b[0m\n",
            "\u001b[34mFILE: EasyNegativeembedings/EasyNegative.pt\u001b[0m\n",
            "\u001b[34mFILE: SomethingV2_2models/SomethingV2_2.safetensors\u001b[0m\n",
            "\u001b[34mFILE: GoodHands-beta2loras/GoodHands-beta2.safetensors\u001b[0m\n",
            "\u001b[34mFILE: vae-ft-mse-840000-ema-prunedvaes/vae-ft-mse-840000-ema-pruned.safetensors\u001b[0m\n",
            "\u001b[33mðŸ Download finished.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbCVq0rCrGPs"
      },
      "source": [
        "**[INDO]**\n",
        "\n",
        "`RESTART RUNTIME` Setelah Menambahkan Bahan untuk generate gambar.\n",
        "\n",
        "**[ENG]**\n",
        "\n",
        "`RESTART THE RUNTIME` After Adding Materials to generate the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atmx0PNQ78Wa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674,
          "referenced_widgets": [
            "188e68e32864442f94aba8b50ded3655",
            "d6610798ec60426fac9695b71f48c180",
            "16fe61ad77c04b1ab464b3bf643614c1",
            "16f640c2a5564e53874b012b2c995e12",
            "25a28fce16db404183d3f5c8b622d347",
            "b93b710d388a46bd83c548e639f36da1",
            "2e5a3a64a9fe4015a9389e425c2d4609",
            "bba242c9f51541f2a0157e1939875109",
            "b35bbc0bd1f34e718a8a72704bf2ff61",
            "b0f751af4de0420e838671f4e76c26f1",
            "aafc2d49df40407a81e6e5db6dae7226",
            "b00f350e773e49708e64094b55e92604",
            "cff722fd37dd4418bf1227f374670faf",
            "a26f666c7b1c41858499a8082ef6f267",
            "b365a794d7604af39beb93d91cb51d66",
            "3e281c93a6ba4486afa7606eac910db5",
            "1647fb539caf482db2503ed6c67c5d31",
            "a4a98849a00345de8fc178326213309b",
            "3fa5eaafcffc439d9ebb3df9a4e00c94",
            "a1bdf7f95b22421f90f79023f9d95e0f",
            "def7fc58d0774c92b7bdc6f5e83b8c8d",
            "8e4e85c5ff444800a8f6d28e5b129e83",
            "9a2ebfef87df4189ad7743c88a435358",
            "de1fd2e2bc374dfc9ff1c159c7d7f9c0",
            "ea149188c8b8457c8372f6a52b1bd636",
            "4b885550478b45d2b8ff19ef9c3a7608",
            "ee6f0fbedd9c4eb895c86c2d0033365f",
            "a4d59d59d4864c48b9c685114adf5f7e",
            "41197c527cd444ba848f36d08f1e7178",
            "0007f640aadf4d058d54a355b392ce48",
            "cd4a052e013e4a83b352450873350564",
            "a347da3b170d4bcf9cf31d01b0621658",
            "a0a5202e25054279b0e671236a042a04",
            "48a9808182bb4f25b2c6e57cb97a8689",
            "7c94b688652e41e99abbc41288e85283",
            "4dd3a95f76244506bf8ca2043559e3c1",
            "0ae94af0c2cc4984a7845759dcde8291",
            "d22d45be453d405f851eb818db953712",
            "dda18d9ae4cd443a99d94a1a37b0cc7a",
            "396fb8fc02ef46e3aff49ae1f2023e64",
            "be7cde45dbe04b6482df780828f90286",
            "576242468ef14f329c43d852296ef5d2",
            "f966c1d6ae3f4e568d445dd7bb812c7e",
            "a57239bbc16c43b38b9cba57efde4fd0",
            "3e7ce5da1f504feebcc320d34283a5b4",
            "24f65b5e26cb4f9ebc441eb616141009",
            "dbcdbcfc0f5944caad2e87787350d4c6",
            "914bb332ef0c49b0849699486b3f9aaa",
            "13c699f5c8fa4698977d3a666f4fc3ab",
            "67b24be8d61e46fcb18c2b77f3fe3982",
            "6cd522def4db4b4b929d8a4aca56c200",
            "eddb672da7dd4ba7a784b68df78d19d4",
            "f836965bce6245019a991111f014b05d",
            "326ab5386cb5487693e719502d886a58",
            "5af20017e1bf419f81007e778e28cf29",
            "58b6e3b9d478499ea7ebc39077ed9a20",
            "134fbbd9c19e4846a3c4ffa5276e05d0",
            "c7206822a62c44fd9631998b8f387399",
            "86c4fa5984f54720b295565b00d2f3a8",
            "d1f9e2eefde94f88b0adbee4fdcfa4b8",
            "70d4010a3ea14ba6acd2caf791b7e9c7",
            "b368b5ca7e2a410c9754082adc9eb060",
            "4be969c512af41a7884141fb40293b83",
            "b50f083edb6c42baa0ea65cee82e058d",
            "aa9a4288ad1749cbaf0093b15d5283a7",
            "0c3e76bbdb434f6f8672b877e07e08af",
            "9be8432c8cf54f95bab615ebe82fe3a7",
            "707e307fc1a44199a8b0bed1d0d10713",
            "ae27791def074e978489458c4cc1ec2b",
            "5302c29c33f24044a4efbeef4a746384",
            "8efdf65e994845bea105fd5104b92901",
            "522d4619aa4b40b089e44cfe600d1e87",
            "745872c7d18041c6b34ff37ed4f4f852",
            "bff88e0e016945689fd959225f6db044",
            "1b2f183c5a27418bbafec9dfc5496cb8",
            "8fda3c34d9f04b01a540aa1ff23d8b21",
            "5ac5f579222f4181b51664978d0c9fab",
            "d984ecc032044784a4d484f2ed7f0331",
            "e624137f08c74151890b507e0e514a52",
            "796340036d07492383b478ff8ff9187d",
            "c7bcacb250ca4cd081859e19593b426a",
            "4f8969a32ca44db8b9384538c982a710",
            "c6696cf8f38249cdaf118c7ae692501b",
            "cc4ac58be35946c7ae9b29c32fd9123a",
            "0be365ae79fd461c83cbcaaf10e1a399",
            "3969d073066f438882e709660e046037",
            "9eef69a3ea604799b32ec1ffee9f58dd",
            "77943f1ca6014e8989f4c13f4645fb72",
            "916e8ca7fe5d454b9d0f04d98da9c203",
            "f9515c5dffc7440a9f210c68e33ae16d",
            "9125952cc46943088eafbb14ae13f788",
            "f5b7d8f3b87e4991a00b4e789f524c28",
            "ca641550cf704a13b4cd2783dacda23c",
            "8d8fe5f89a0149c3a07747b88b3e0e7b",
            "965e9ce3d4684b05b7af64bc20b6cc14",
            "54ca212901b24621b8a6d87a7da3847f",
            "8b997e3c5227473e9a8ad0afe7c5a12b",
            "2b529514bc974a1b9f0f8512bc42209b",
            "1597f8cfb8a543e69fa13029263f8ca2",
            "0ba9838d682546df839bfdb07e231c8e",
            "fb1a9c9f12854f0197f03bbeeb0cdd43",
            "461323b420f5460da913529f31c9e0f5",
            "930e3ebf8d8e476297f14130ace761ca",
            "a4fa85f88f91415297f1deeaa857e875",
            "73932b7f940643f7a03ea347efd26024",
            "0e2c5bf2d1264c16a3621f50c976758d",
            "9fe5e811f1754c9ba8440600c453eac8",
            "5720cfa0fa6e47b5a7aaaffacbfbaa4d",
            "429faec8806347a6945b73dca8761b68",
            "7a3b67c441ec4cb0aaa35728b2e6f681",
            "6c0ede588db647098de1ba53691cd753"
          ]
        },
        "outputId": "d5602924-f234-4047-d9f8-39f368504415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(AppLayout(children=(HTML(value='<h2>Stable Diffusion Lite [Vorst Cavry]</h2>', layout=Layout(grâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "188e68e32864442f94aba8b50ded3655"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title ðŸ‘‡ Generating Images <font color=\"#90EE90\"><font size=\"2\"><b>[RESTART RUNTIME]<b>{ form-width: \"20%\", display-mode: \"form\" }\n",
        "#@markdown **[INDO]**\n",
        "#@markdown ---\n",
        "#@markdown - **Prompt** - Deskripsi gambar\n",
        "#@markdown - **Prompt Negatif** - Hal-hal yang tidak ingin Anda lihat atau abaikan dalam gambar\n",
        "#@markdown - **Langkah** - Jumlah langkah denoising. Langkah yang lebih tinggi dapat menghasilkan hasil yang lebih baik tetapi membutuhkan waktu lebih lama untuk menghasilkan gambar. Standarnya adalah `30`.\n",
        "#@markdown - **CFG** - Skala panduan mulai dari `0` hingga `20`. Nilai yang lebih rendah memungkinkan AI menjadi lebih kreatif dan tidak terlalu ketat dalam mengikuti perintah. Nilai default adalah `7,5`.\n",
        "#@markdown - **Pilih Sampler** - Daftar penjadwal yang dapat dipilih.\n",
        "#@markdown - **Seed** - Nilai acak yang mengontrol pembuatan gambar. Seed dan prompt yang sama menghasilkan gambar yang sama. Tetapkan `-1` untuk menggunakan nilai seed acak.\n",
        "#@markdown ---\n",
        "#@markdown **[ENG]**\n",
        "#@markdown ---\n",
        "#@markdown - **Prompt** - Description of the image\n",
        "#@markdown - **Negative Prompt** - Things you don't want to see or ignore in the image\n",
        "#@markdown - **Steps** - Number of denoising steps. Higher steps may lead to better results but takes longer time to generate the image. Default is `30`.\n",
        "#@markdown - **CFG** - Guidance scale ranging from `0` to `20`. Lower values allow the AI to be more creative and less strict at following the prompt. Default is `7.5`.\n",
        "#@markdown - **Select Sampler** - A list of schedulers to choose from.\n",
        "#@markdown - **Seed** - A random value that controls image generation. The same seed and prompt produce the same images. Set `-1` for using random seed values.\n",
        "#@markdown ---\n",
        "%cd /content\n",
        "import ipywidgets as widgets, mediapy, random\n",
        "from diffusers.models.attention_processor import AttnProcessor2_0\n",
        "from PIL import Image\n",
        "import IPython.display\n",
        "from diffusers import (\n",
        "    DPMSolverMultistepScheduler,\n",
        "    DPMSolverSinglestepScheduler,\n",
        "    KDPM2DiscreteScheduler,\n",
        "    KDPM2AncestralDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    HeunDiscreteScheduler,\n",
        "    LMSDiscreteScheduler,\n",
        "    DDIMScheduler,\n",
        "    DiffusionPipeline,\n",
        ")\n",
        "\n",
        "#from IPython.display import display\n",
        "from ipywidgets import interactive, Layout, VBox\n",
        "\n",
        "#Get scheduler\n",
        "def get_scheduler(name):\n",
        "\n",
        "  match name:\n",
        "\n",
        "    case \"DPM++ 2M\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config)\n",
        "\n",
        "    case \"DPM++ 2M Karras\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"DPM++ 2M SDE\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config, algorithm_type=\"sde-dpmsolver++\")\n",
        "\n",
        "    case \"DPM++ 2M SDE Karras\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True, algorithm_type=\"sde-dpmsolver++\")\n",
        "\n",
        "    case \"DPM++ SDE\":\n",
        "      return DPMSolverSinglestepScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"DPM++ SDE Karras\":\n",
        "      return DPMSolverSinglestepScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"DPM2\":\n",
        "      return KDPM2DiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"DPM2 Karras\":\n",
        "      return KDPM2DiscreteScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"Euler\":\n",
        "      return EulerDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"Euler a\":\n",
        "      return EulerAncestralDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"Heun\":\n",
        "      return HeunDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"LMS\":\n",
        "      return LMSDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"LMS Karras\":\n",
        "      return LMSDiscreteScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"DDIMScheduler\":\n",
        "      return DDIMScheduler.from_config(model.pipe.scheduler.config)\n",
        "\n",
        "#PARAMETER WIDGETS\n",
        "width = \"250px\"\n",
        "\n",
        "select_model = widgets.Dropdown(\n",
        "    options=model_list,\n",
        "    description=\"Select Model:\"\n",
        ")\n",
        "\n",
        "vae_model_dropdown = widgets.Dropdown(\n",
        "    options=vae_model_list,\n",
        "    description=\"Select VAE:\"\n",
        ")\n",
        "\n",
        "prompt = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter prompt\",\n",
        "    #description=\"Prompt:\",\n",
        "    rows=5,\n",
        "    layout=widgets.Layout(width=\"600px\")\n",
        ")\n",
        "\n",
        "neg_prompt = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter negative prompt\",\n",
        "    #description=\"Negative Prompt:\",\n",
        "    rows=5,\n",
        "    layout=widgets.Layout(width=\"600px\")\n",
        ")\n",
        "\n",
        "num_images = widgets.IntText(\n",
        "    value=1,\n",
        "    description=\"Images:\",\n",
        "    layout=widgets.Layout(width=width),\n",
        ")\n",
        "\n",
        "steps = widgets.IntText(\n",
        "    value=30,\n",
        "    description=\"Steps:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "CFG = widgets.FloatText(\n",
        "    value=7.5,\n",
        "    description=\"CFG:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "select_sampler = widgets.Dropdown(\n",
        "    options=[\n",
        "        \"DPM++ 2M\",\n",
        "        \"DPM++ 2M Karras\",\n",
        "        \"DPM++ 2M SDE\",\n",
        "        \"DPM++ 2M SDE Karras\",\n",
        "        \"DPM++ SDE\",\n",
        "        \"DPM++ SDE Karras\",\n",
        "        \"DPM2\",\n",
        "        \"DPM2 Karras\",\n",
        "        \"Euler\",\n",
        "        \"Euler a\",\n",
        "        \"Heun\",\n",
        "        \"LMS\",\n",
        "        \"LMS Karras\",\n",
        "        \"DDIMScheduler\",\n",
        "    ],\n",
        "    description=\"Scheduler:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "select_sampler.style.description_width = \"auto\"\n",
        "\n",
        "img_height = widgets.IntText(\n",
        "    min=256,\n",
        "    max=2048,\n",
        "    value=512,\n",
        "    description=\"Height:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "img_width = widgets.IntText(\n",
        "    min=256,\n",
        "    max=2048,\n",
        "    value=512,\n",
        "    description=\"Width:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "random_seed = widgets.IntText(\n",
        "    value=-1,\n",
        "    description=\"Seed:\",\n",
        "    layout=widgets.Layout(width=width),\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "generate = widgets.Button(\n",
        "    description=\"Generate\",\n",
        "    disabled=False,\n",
        "    button_style=\"primary\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "#lora1\n",
        "select_lora1 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora1:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "lora_weights_scale1 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    description=\"Lora scale1:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "#lora2\n",
        "select_lora2 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora2:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "lora_weights_scale2 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    description=\"Lora scale2:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "#lora3\n",
        "select_lora3 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora3:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "lora_weights_scale3 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    description=\"Lora scale3:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "display_imgs = widgets.Output()\n",
        "\n",
        "\n",
        "### second part ####\n",
        "preprocess_resolution_global = widgets.IntSlider(\n",
        "    value=512,\n",
        "    min=256,\n",
        "    max=2048,\n",
        "    description='Preprocess resolution ControlNet'\n",
        ")\n",
        "\n",
        "control_model_list = list(CONTROLNET_MODEL_IDS.keys())\n",
        "\n",
        "# Create a Dropdown for selecting options\n",
        "options_controlnet = widgets.Dropdown(\n",
        "    options=[\n",
        "        control_model_list[13],\n",
        "        control_model_list[0],\n",
        "        control_model_list[1],\n",
        "        control_model_list[2],\n",
        "        control_model_list[3],\n",
        "        control_model_list[4],\n",
        "        control_model_list[5],\n",
        "        control_model_list[6],\n",
        "        control_model_list[7],\n",
        "        control_model_list[8],\n",
        "        control_model_list[10],\n",
        "        control_model_list[11]\n",
        "    ],\n",
        "    description='TASK:',\n",
        ")\n",
        "\n",
        "# Create a dictionary to map options to lists of IntText widgets\n",
        "int_inputs = {\n",
        "\n",
        "    control_model_list[13]: [\n",
        "    ],\n",
        "    control_model_list[0]: [\n",
        "        widgets.Dropdown(value='Openpose', description='Preprocessor:', options=['None','Openpose'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[1]: [\n",
        "        widgets.IntText(value=100, min=1, max=255, description='Canny low threshold:', layout=Layout(visibility='hidden')),\n",
        "        widgets.IntText(value=200, min=1, max=255, description='Canny high threshold:', layout=Layout(visibility='hidden'))\n",
        "    ],\n",
        "    control_model_list[2]: [\n",
        "        widgets.FloatText(value=0.1, min=1, max=2.0, description='Hough value threshold (MLSD):', layout=Layout(visibility='hidden')),\n",
        "        widgets.FloatText(value=0.1, min=1, max=20.0, description='Hough distance threshold (MLSD):', layout=Layout(visibility='hidden'))\n",
        "    ],\n",
        "    control_model_list[3]: [\n",
        "        widgets.Dropdown(value='HED', description='Preprocessor:', options=['HED','PidiNet', 'None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[4]: [\n",
        "        widgets.Dropdown(value='PidiNet', description='Preprocessor:', options=['HED','PidiNet', 'HED safe', 'PidiNet safe','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[5]: [\n",
        "        widgets.Dropdown(value='UPerNet', description='Preprocessor:', options=['UPerNet','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[6]: [\n",
        "        widgets.Dropdown(value='DPT', description='Preprocessor:', options=['Midas', 'DPT','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[7]: [\n",
        "        widgets.Dropdown(value='NormalBae', description='Preprocessor:', options=['NormalBae','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[8]: [\n",
        "        widgets.Dropdown(value='Lineart', description='Preprocessor:', options=['Lineart','Lineart coarse', 'None', 'Lineart (anime)', 'None (anime)'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[10]: [\n",
        "        widgets.Dropdown(value='ContentShuffle', description='Preprocessor:', options=['ContentShuffle','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Create the FileUpload widget\n",
        "# file_upload_widget = widgets.FileUpload(\n",
        "#     accept='',       # Accepted file extension\n",
        "#     multiple=False,  # Allow multiple file uploads\n",
        "#     disabled=False   # Initially disable the widget\n",
        "# )\n",
        "\n",
        "# Function to update visibility and enable/disable state of widgets\n",
        "def update_widgets(option):\n",
        "    for opt, int_inputs_list in int_inputs.items():\n",
        "        if opt == option:\n",
        "            for int_input in int_inputs_list:\n",
        "                int_input.layout.visibility = 'visible'\n",
        "        else:\n",
        "            for int_input in int_inputs_list:\n",
        "                int_input.layout.visibility = 'hidden'\n",
        "                #int_input.value = 0  # Reset the value when hiding\n",
        "    #enable_checkbox_controlnet.value = False  # Disable file upload when changing options\n",
        "    #print(file_upload_widget.value)\n",
        "    # file_upload_widget.value.clear()\n",
        "    # file_upload_widget._counter=0\n",
        "\n",
        "interactive(update_widgets, option=options_controlnet)\n",
        "\n",
        "# Create a layout container to hold all the widgets\n",
        "#widget_container_controlnet = VBox([enable_checkbox_controlnet, options_controlnet] + [int_input for int_inputs_list in int_inputs.values() for int_input in int_inputs_list] + [file_upload_widget])\n",
        "\n",
        "### RUN ###\n",
        "\n",
        "# model_default = next(iter(model_list))\n",
        "# print(f\"Loading {model_default[0]}\")\n",
        "# model = Model(base_model_id=model_default[1], task_name='img2img')\n",
        "\n",
        "\n",
        "def generate_img(i):\n",
        "  global model\n",
        "  #Clear output\n",
        "  display_imgs.clear_output()\n",
        "  generate.disabled = True\n",
        "\n",
        "  #Calculate seed\n",
        "  seed = random.randint(0, 2147483647) if random_seed.value == -1 else random_seed.value\n",
        "\n",
        "  with display_imgs:\n",
        "\n",
        "    print(\"Running...\")\n",
        "\n",
        "\n",
        "    # First load\n",
        "    try:\n",
        "        model\n",
        "    except:\n",
        "        model = Model(base_model_id=select_model.value, task_name=options_controlnet.value, vae_model = vae_model_dropdown.value)\n",
        "\n",
        "    model.load_pipe(select_model.value, task_name=options_controlnet.value, vae_model = vae_model_dropdown.value)\n",
        "\n",
        "    display_imgs.clear_output()\n",
        "\n",
        "    model.pipe.to(\"cuda\")\n",
        "    model.pipe.unfuse_lora()\n",
        "    model.pipe.unload_lora_weights()\n",
        "\n",
        "    if select_lora1.value != \"None\":\n",
        "      print('lora1')\n",
        "      model.pipe.load_lora_weights(select_lora1.value)\n",
        "      model.pipe.fuse_lora(lora_scale=lora_weights_scale1.value)\n",
        "    if select_lora2.value != \"None\":\n",
        "      print('lora2')\n",
        "      model.pipe.load_lora_weights(select_lora2.value)\n",
        "      model.pipe.fuse_lora(lora_scale=lora_weights_scale1.value)\n",
        "    if select_lora3.value != \"None\":\n",
        "      print('lora3')\n",
        "      model.pipe.load_lora_weights(select_lora3.value)\n",
        "      model.pipe.fuse_lora(lora_scale=lora_weights_scale1.value)\n",
        "\n",
        "    model.pipe.enable_xformers_memory_efficient_attention()\n",
        "    model.pipe.scheduler = get_scheduler(select_sampler.value)\n",
        "    model.pipe.safety_checker = None\n",
        "\n",
        "    if options_controlnet.value != 'txt2img':\n",
        "        print(f'Control image: {destination_path_cn_img}')\n",
        "        image_pil = Image.open(destination_path_cn_img)\n",
        "        numpy_array = np.array(image_pil, dtype=np.uint8)\n",
        "        array_rgb = numpy_array[:, :, :3]\n",
        "\n",
        "    if options_controlnet.value == 'txt2img':\n",
        "\n",
        "        images = model.pipe(\n",
        "          prompt.value,\n",
        "          height = img_height.value,\n",
        "          width = img_width.value,\n",
        "          num_inference_steps = steps.value,\n",
        "          guidance_scale = CFG.value,\n",
        "          num_images_per_prompt = num_images.value,\n",
        "          negative_prompt = neg_prompt.value,\n",
        "          generator = torch.Generator(\"cuda\").manual_seed(seed),\n",
        "        ).images\n",
        "\n",
        "    elif options_controlnet.value == 'Openpose':\n",
        "        print('BETA: Openpose, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_openpose(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['Openpose'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'Canny':\n",
        "        print('BETA: Canny')\n",
        "\n",
        "        images = model.process_canny(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            low_threshold=int_inputs['Canny'][0].value,\n",
        "            high_threshold=int_inputs['Canny'][1].value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'MLSD':\n",
        "        print('BETA: MLSD')\n",
        "\n",
        "        images = model.process_mlsd(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            value_threshold=int_inputs['MLSD'][0].value,\n",
        "            distance_threshold=int_inputs['MLSD'][1].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'scribble':\n",
        "        print('BETA: scribble, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_scribble(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['scribble'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'softedge':\n",
        "        print('BETA: softedge, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_softedge(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['softedge'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'segmentation':\n",
        "        print('BETA: segmentation, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_segmentation(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['segmentation'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'depth':\n",
        "        print('BETA: depth, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_depth(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['depth'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'NormalBae':\n",
        "        print('BETA: NormalBae, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_mlsd(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['NormalBae'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif 'lineart' in options_controlnet.value:\n",
        "        print('BETA: lineart, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_lineart(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['lineart'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'shuffle':\n",
        "        print('BETA: shuffle, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_shuffle(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['shuffle'][0].value,\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'ip2p':\n",
        "        print('BETA: (inpaint pix2pix) ip2p, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_ip2p(\n",
        "            image=array_rgb,\n",
        "            prompt=prompt.value,\n",
        "            additional_prompt=\"\",\n",
        "            negative_prompt=neg_prompt.value,\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "        )\n",
        "\n",
        "    else:\n",
        "      images = None\n",
        "\n",
        "    if select_lora1.value != \"None\":\n",
        "        model.pipe.unfuse_lora()\n",
        "        model.pipe.unload_lora_weights()\n",
        "    if select_lora2.value != \"None\" or select_lora3.value != \"None\":\n",
        "        print('BETA: reload weights for lora')\n",
        "        model.load_pipe(select_model.value, task_name=options_controlnet.value, vae_model = vae_model_dropdown.value, reload=True)\n",
        "\n",
        "    model.pipe.unfuse_lora()\n",
        "    model.pipe.unload_lora_weights()\n",
        "\n",
        "    mediapy.show_images(images)\n",
        "\n",
        "    # Save img\n",
        "    import re\n",
        "    def slugify(text, replacement='_'):\n",
        "        return re.sub(r'[\\/:*?\"<>|]', replacement, text)\n",
        "    global image_list\n",
        "    image_list = []\n",
        "    directory_images = 'images'\n",
        "    os.makedirs(directory_images, exist_ok=True)\n",
        "\n",
        "    images = [images[1]] if options_controlnet.value != 'txt2img' else images\n",
        "\n",
        "    for idx, (image,prompt_i) in enumerate(zip(images, [prompt.value[:30]*(num_images.value)])):\n",
        "        print(slugify(prompt_i))\n",
        "        image_name = f'{slugify(prompt_i)}-seed{seed}-{idx}.png'\n",
        "        image_path = directory_images + '/' + image_name\n",
        "\n",
        "        if os.path.exists(image_path):\n",
        "            random_number = random.randint(1, 100000)\n",
        "            image_name = f'{slugify(prompt_i)}-seed{seed}-{idx} random_number{str(random_number)}.png'\n",
        "            image_path = directory_images + '/' + image_name\n",
        "        image.save(image_path)\n",
        "        image_list.append(image_path)\n",
        "\n",
        "    #print(pipe.scheduler)\n",
        "    print(f\"Seed:\\n{seed}\")\n",
        "\n",
        "  generate.disabled = False\n",
        "\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def display_text_box(content, width=\"485px\", height=\"30px\"):\n",
        "    html_content = f'''\n",
        "        <div style=\"\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            justify-content: center;\n",
        "            border: 2px solid #ccc;\n",
        "            background-color: #007bff;\n",
        "            width: {width};\n",
        "            height: {height};\n",
        "            color: white;\n",
        "            font-weight: bold;\n",
        "            text-align: center;\n",
        "        \">{content}</div>\n",
        "    '''\n",
        "    display(HTML(html_content))\n",
        "\n",
        "text_content = \"Terima kasih Telah Menggunakan Notebook google colab StableDiffusion milik Remaja Pekalongan.\"\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import HTML, Image\n",
        "\n",
        "def display_image():\n",
        "    image_url = \"https://i.postimg.cc/Pf3XXMsP/Cuplikan-layar-2023-07-30-165548.png\"\n",
        "    image_html = f'<a href=\"https://www.youtube.com/@remajapekalongan\" target=\"_blank\"><img src=\"{image_url}\" width=\"489\" height=\"172\"></a>'\n",
        "\n",
        "    display(HTML(image_html))\n",
        "\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def create_button_with_link(label, link):\n",
        "    button_id = label.lower().replace(\" \", \"_\")\n",
        "    return f'''\n",
        "        <style>\n",
        "            #{button_id} {{\n",
        "                width: 119px;\n",
        "                height: 40px;\n",
        "                background-color: #007bff;\n",
        "                color: white;\n",
        "                border: 2px solid #ccc;\n",
        "                cursor: pointer;\n",
        "                transition: background-color 0.3s;\n",
        "            }}\n",
        "            #{button_id}:hover {{\n",
        "                background-color: #0056b3;\n",
        "            }}\n",
        "        </style>\n",
        "        <a href=\"{link}\" target=\"_blank\" style=\"text-decoration: none;\">\n",
        "            <button id=\"{button_id}\">{label}</button>\n",
        "        </a>\n",
        "    '''\n",
        "\n",
        "subscribe_button = create_button_with_link(\"Subscribe\", \"https://www.youtube.com/@remajapekalongan\")\n",
        "support_button = create_button_with_link(\"Support\", \"https://ko-fi.com/vorstcavry\")\n",
        "saweria_button = create_button_with_link(\"Saweria\", \"https://http://saweria.co/vorstcavry\")\n",
        "discord_button = create_button_with_link(\"Discord\", \"https://discord.gg/fg9kvMqUmD\")\n",
        "\n",
        "buttons_html = f'<div>{subscribe_button} {support_button} {saweria_button} {discord_button}</div>'\n",
        "\n",
        "#Display\n",
        "generate.on_click(generate_img)\n",
        "\n",
        "widgets.VBox(\n",
        "    [\n",
        "      widgets.AppLayout(\n",
        "        header=widgets.HTML(\n",
        "            value=\"<h1>Image Generated Interactive Lite[Vorst Cavry]</h1>\",\n",
        "        ),\n",
        "        left_sidebar=widgets.VBox(\n",
        "            [\n",
        "                select_model,\n",
        "                vae_model_dropdown,\n",
        "                num_images, steps,\n",
        "                CFG, select_sampler,\n",
        "                img_height, img_width,\n",
        "                random_seed,\n",
        "                select_lora1,\n",
        "                lora_weights_scale1,\n",
        "                select_lora2,\n",
        "                lora_weights_scale2,\n",
        "                select_lora3,\n",
        "                lora_weights_scale3,\n",
        "            ]\n",
        "        ),\n",
        "        center=widgets.VBox(\n",
        "            [prompt, neg_prompt, generate]\n",
        "        ),\n",
        "\n",
        "        right_sidebar=widgets.VBox([preprocess_resolution_global, options_controlnet] + [int_input for int_inputs_list in int_inputs.values() for int_input in int_inputs_list] ),\n",
        "        footer=None\n",
        "      ),\n",
        "      display_imgs\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ‘‡ Generating Images V2 { form-width: \"20%\", display-mode: \"form\" }\n",
        "#@markdown <b>[IND]</b>\n",
        "#@markdown ---\n",
        "#@markdown - **Prompt** - Deskripsi gambar\n",
        "#@markdown - **Prompt Negatif** - Hal-hal yang tidak ingin Anda lihat atau abaikan dalam gambar\n",
        "#@markdown - **Langkah** - Jumlah langkah denoising. Langkah yang lebih tinggi dapat menghasilkan hasil yang lebih baik tetapi membutuhkan waktu lebih lama untuk menghasilkan gambar. Standarnya adalah `30`.\n",
        "#@markdown - **CFG** - Skala panduan mulai dari `0` hingga `20`. Nilai yang lebih rendah memungkinkan AI menjadi lebih kreatif dan tidak terlalu ketat dalam mengikuti perintah. Nilai default adalah `7,5`.\n",
        "#@markdown - **Sampler** - Penjadwal bertanggung jawab untuk mengontrol laju pembelajaran model difusi. Penjadwal yang berbeda dapat menghasilkan hasil yang berbeda, jadi penting untuk memilih penjadwal yang sesuai untuk tugas yang diinginkan.\n",
        "#@markdown - **Seed** - Nilai acak yang mengontrol pembuatan gambar. Seed dan prompt yang sama akan menghasilkan gambar yang sama. Tetapkan `-1` untuk menggunakan nilai seed acak.\n",
        "#@markdown - **Bobot prompt** - Merupakan cara untuk mengontrol pengaruh prompt teks yang berbeda pada proses pembuatan gambar. Prompt weights dapat digunakan untuk menekankan atau menghilangkan penekanan pada aspek tertentu gambar, misalnya, objek, pemandangan, atau gaya. Saat ini, yang digunakan yaitu [Compel syntax](https://github.com/damian0815/compel/blob/main/doc/syntax.md). Anda juga dapat mengaktifkan `Convert Prompt weights` untuk secara otomatis mengonversi sintaks dari `(word:1.1)` ke `(word)1.1` atau `(word)` ke `(word)+` agar kompatibel dengan bobot Compel. Compel menskalakan lebih banyak dengan nilainya sehingga lebih sedikit bobot n\n",
        "#@markdown ---\n",
        "#@markdown <b>[ENG]</b>\n",
        "#@markdown ---\n",
        "#@markdown - **Prompt** - Description of the image\n",
        "#@markdown - **Negative Prompt** - Things you don't want to see or ignore in the image\n",
        "#@markdown - **Steps** - Number of denoising steps. Higher steps may lead to better results but takes longer time to generate the image. Default is `30`.\n",
        "#@markdown - **CFG** - Guidance scale ranging from `0` to `20`. Lower values allow the AI to be more creative and less strict at following the prompt. Default is `7.5`.\n",
        "#@markdown - **Sampler** - The scheduler is responsible for controlling the learning rate of the diffusion model. Different schedulers can produce different results, so it is important to choose a scheduler that is appropriate for the desired task.\n",
        "#@markdown - **Seed** - A random value that controls image generation. The same seed and prompt produce the same images. Set `-1` for using random seed values.\n",
        "#@markdown - **Prompt weights** -  Are a way to control the influence of different text prompts on the image generation process. Prompt weights can be used to emphasize or de-emphasize certain aspects of the image, such as the object, the scene, or the style. Currently, the [Compel syntax](https://github.com/damian0815/compel/blob/main/doc/syntax.md) is being used. You can also activate the `Convert Prompt weights` to automatically convert syntax from `(word:1.1)` to `(word)1.1` or `(word)` to `(word)+` to make them compatible with Compel weights. Compel scale more with its values so that fewer weights are needed for good results\n",
        "#@markdown - **ControlNet** - Is a neural network model for controlling diffusion models. It allows users to input additional information, such as edge maps, segmentation maps, and key points, into diffusion models to guide the image generation process.\n",
        "#@markdown ---\n",
        "%cd /content\n",
        "import ipywidgets as widgets, mediapy, random\n",
        "from diffusers.models.attention_processor import AttnProcessor2_0\n",
        "from PIL import Image\n",
        "import IPython.display\n",
        "from diffusers import (\n",
        "    DPMSolverMultistepScheduler,\n",
        "    DPMSolverSinglestepScheduler,\n",
        "    KDPM2DiscreteScheduler,\n",
        "    KDPM2AncestralDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    HeunDiscreteScheduler,\n",
        "    LMSDiscreteScheduler,\n",
        "    DDIMScheduler,\n",
        "    DiffusionPipeline,\n",
        ")\n",
        "import time\n",
        "from IPython.utils import capture\n",
        "import logging\n",
        "logging.getLogger(\"diffusers\").setLevel(logging.ERROR)\n",
        "\n",
        "#from IPython.display import display\n",
        "from ipywidgets import interactive, Layout, VBox\n",
        "\n",
        "#Get scheduler\n",
        "def get_scheduler(name):\n",
        "\n",
        "  match name:\n",
        "\n",
        "    case \"DPM++ 2M\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config)\n",
        "\n",
        "    case \"DPM++ 2M Karras\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"DPM++ 2M SDE\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config, algorithm_type=\"sde-dpmsolver++\")\n",
        "\n",
        "    case \"DPM++ 2M SDE Karras\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True, algorithm_type=\"sde-dpmsolver++\")\n",
        "\n",
        "    case \"DPM++ SDE\":\n",
        "      return DPMSolverSinglestepScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"DPM++ SDE Karras\":\n",
        "      return DPMSolverSinglestepScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"DPM2\":\n",
        "      return KDPM2DiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"DPM2 Karras\":\n",
        "      return KDPM2DiscreteScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"Euler\":\n",
        "      return EulerDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"Euler a\":\n",
        "      return EulerAncestralDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"Heun\":\n",
        "      return HeunDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"LMS\":\n",
        "      return LMSDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"LMS Karras\":\n",
        "      return LMSDiscreteScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"DDIMScheduler\":\n",
        "      return DDIMScheduler.from_config(model.pipe.scheduler.config)\n",
        "\n",
        "#PARAMETER WIDGETS\n",
        "width = \"250px\"\n",
        "\n",
        "select_model = widgets.Dropdown(\n",
        "    options=model_list,\n",
        "    description=\"Model:\"\n",
        ")\n",
        "\n",
        "vae_model_dropdown = widgets.Dropdown(\n",
        "    options=vae_model_list,\n",
        "    description=\"VAE:\"\n",
        ")\n",
        "\n",
        "prompt = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter prompt\",\n",
        "    #description=\"Prompt:\",\n",
        "    rows=5,\n",
        "    layout=widgets.Layout(width=\"550px\")\n",
        ")\n",
        "\n",
        "neg_prompt = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter negative prompt\",\n",
        "    #description=\"Negative Prompt:\",\n",
        "    rows=5,\n",
        "    layout=widgets.Layout(width=\"550px\")\n",
        ")\n",
        "\n",
        "num_images = widgets.IntText(\n",
        "    value=1,\n",
        "    description=\"Images:\",\n",
        "    layout=widgets.Layout(width=width),\n",
        ")\n",
        "\n",
        "steps = widgets.IntText(\n",
        "    value=30,\n",
        "    description=\"Steps:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "CFG = widgets.FloatText(\n",
        "    value=7.5,\n",
        "    step=0.5,\n",
        "    description=\"CFG:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "select_sampler = widgets.Dropdown(\n",
        "    options=[\n",
        "        \"DPM++ 2M\",\n",
        "        \"DPM++ 2M Karras\",\n",
        "        \"DPM++ 2M SDE\",\n",
        "        \"DPM++ 2M SDE Karras\",\n",
        "        \"DPM++ SDE\",\n",
        "        \"DPM++ SDE Karras\",\n",
        "        \"DPM2\",\n",
        "        \"DPM2 Karras\",\n",
        "        \"Euler\",\n",
        "        \"Euler a\",\n",
        "        \"Heun\",\n",
        "        \"LMS\",\n",
        "        \"LMS Karras\",\n",
        "        \"DDIMScheduler\",\n",
        "    ],\n",
        "    description=\"Scheduler:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "select_sampler.style.description_width = \"auto\"\n",
        "\n",
        "img_height = widgets.IntText(\n",
        "    min=256,\n",
        "    max=2048,\n",
        "    value=512,\n",
        "    description=\"Height:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "img_width = widgets.IntText(\n",
        "    min=256,\n",
        "    max=2048,\n",
        "    value=512,\n",
        "    description=\"Width:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "random_seed = widgets.IntText(\n",
        "    value=-1,\n",
        "    description=\"Seed:\",\n",
        "    layout=widgets.Layout(width=width),\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "generate = widgets.Button(\n",
        "    description=\"Generate\",\n",
        "    disabled=False,\n",
        "    button_style=\"primary\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "# textual inversion\n",
        "show_textual_inversion = widgets.Button(\n",
        "    description=\"List available textual inversions\",\n",
        "    disabled=False,\n",
        "    button_style=\"info\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "active_ti = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Active Textual Inversion in prompt (Experimental)',\n",
        ")\n",
        "# alternative prompt weights\n",
        "weights_prompt = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Convert Prompt weights',\n",
        ")\n",
        "\n",
        "#lora1\n",
        "select_lora1 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora1:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "lora_weights_scale1 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    description=\"Lora scale1:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "#lora2\n",
        "select_lora2 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora2:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "lora_weights_scale2 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    description=\"Lora scale2:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "#lora3\n",
        "select_lora3 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora3:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "lora_weights_scale3 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    description=\"Lora scale3:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "display_imgs = widgets.Output()\n",
        "\n",
        "\n",
        "### second part ####\n",
        "preprocess_resolution_global = widgets.IntSlider(\n",
        "    value=512,\n",
        "    min=256,\n",
        "    max=2048,\n",
        "    description='Preprocess resolution ControlNet'\n",
        ")\n",
        "\n",
        "control_model_list = list(CONTROLNET_MODEL_IDS.keys())\n",
        "\n",
        "# Create a Dropdown for selecting options\n",
        "options_controlnet = widgets.Dropdown(\n",
        "    options=[\n",
        "        control_model_list[13],\n",
        "        control_model_list[0],\n",
        "        control_model_list[1],\n",
        "        control_model_list[2],\n",
        "        control_model_list[3],\n",
        "        control_model_list[4],\n",
        "        control_model_list[5],\n",
        "        control_model_list[6],\n",
        "        control_model_list[7],\n",
        "        control_model_list[8],\n",
        "        control_model_list[10],\n",
        "        control_model_list[11]\n",
        "    ],\n",
        "    description='TASK:',\n",
        "    layout=widgets.Layout(width=\"550px\"),\n",
        ")\n",
        "\n",
        "# Create a dictionary to map options to lists of IntText widgets\n",
        "int_inputs = {\n",
        "\n",
        "    control_model_list[13]: [\n",
        "    ],\n",
        "    control_model_list[0]: [\n",
        "        widgets.Dropdown(value='Openpose', description='Preprocessor:', options=['None','Openpose'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[1]: [\n",
        "        widgets.IntText(value=100, min=1, max=255, description='Canny low threshold:', layout=Layout(visibility='hidden')),\n",
        "        widgets.IntText(value=200, min=1, max=255, description='Canny high threshold:', layout=Layout(visibility='hidden'))\n",
        "    ],\n",
        "    control_model_list[2]: [\n",
        "        widgets.FloatText(value=0.1, min=1, max=2.0, description='Hough value threshold (MLSD):', layout=Layout(visibility='hidden')),\n",
        "        widgets.FloatText(value=0.1, min=1, max=20.0, description='Hough distance threshold (MLSD):', layout=Layout(visibility='hidden'))\n",
        "    ],\n",
        "    control_model_list[3]: [\n",
        "        widgets.Dropdown(value='HED', description='Preprocessor:', options=['HED','PidiNet', 'None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[4]: [\n",
        "        widgets.Dropdown(value='PidiNet', description='Preprocessor:', options=['HED','PidiNet', 'HED safe', 'PidiNet safe','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[5]: [\n",
        "        widgets.Dropdown(value='UPerNet', description='Preprocessor:', options=['UPerNet','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[6]: [\n",
        "        widgets.Dropdown(value='DPT', description='Preprocessor:', options=['Midas', 'DPT','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[7]: [\n",
        "        widgets.Dropdown(value='NormalBae', description='Preprocessor:', options=['NormalBae','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[8]: [\n",
        "        widgets.Dropdown(value='Lineart', description='Preprocessor:', options=['Lineart','Lineart coarse', 'None', 'Lineart (anime)', 'None (anime)'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[10]: [\n",
        "        widgets.Dropdown(value='ContentShuffle', description='Preprocessor:', options=['ContentShuffle','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Function to update visibility and enable/disable state of widgets\n",
        "def update_widgets(option):\n",
        "    for opt, int_inputs_list in int_inputs.items():\n",
        "        if opt == option:\n",
        "            for int_input in int_inputs_list:\n",
        "                int_input.layout.visibility = 'visible'\n",
        "        else:\n",
        "            for int_input in int_inputs_list:\n",
        "                int_input.layout.visibility = 'hidden'\n",
        "\n",
        "interactive(update_widgets, option=options_controlnet)\n",
        "\n",
        "### GENERATE ###\n",
        "\n",
        "def generate_img(i):\n",
        "  global model\n",
        "  #Clear output\n",
        "  display_imgs.clear_output()\n",
        "  generate.disabled = True\n",
        "\n",
        "  #Calculate seed\n",
        "  seed = random.randint(0, 2147483647) if random_seed.value == -1 else random_seed.value\n",
        "\n",
        "  with display_imgs:\n",
        "\n",
        "    print(\"Running...\")\n",
        "\n",
        "\n",
        "    # First load\n",
        "    try:\n",
        "        model\n",
        "    except:\n",
        "        model = Model(base_model_id=select_model.value, task_name=options_controlnet.value, vae_model = vae_model_dropdown.value)\n",
        "\n",
        "    model.load_pipe(select_model.value, task_name=options_controlnet.value, vae_model = vae_model_dropdown.value)\n",
        "\n",
        "    display_imgs.clear_output()\n",
        "\n",
        "    model.pipe.to(\"cuda\")\n",
        "    # model.pipe.unfuse_lora()\n",
        "    # model.pipe.unload_lora_weights()\n",
        "\n",
        "    if select_lora1.value != \"None\":\n",
        "      print('lora1')\n",
        "      try:\n",
        "          model.pipe.load_lora_weights(select_lora1.value)\n",
        "          model.pipe.fuse_lora(lora_scale=lora_weights_scale1.value)\n",
        "      except:\n",
        "          print(f\"ERROR: LoRA not compatible  {select_lora1.value}:\")\n",
        "          del model\n",
        "          generate.disabled = False\n",
        "          return\n",
        "\n",
        "    if select_lora2.value != \"None\":\n",
        "      print('lora2')\n",
        "      try:\n",
        "          model.pipe.load_lora_weights(select_lora2.value)\n",
        "          model.pipe.fuse_lora(lora_scale=lora_weights_scale2.value)\n",
        "      except:\n",
        "          print(f\"ERROR: LoRA not compatible  {select_lora2.value}:\")\n",
        "          del model\n",
        "          generate.disabled = False\n",
        "          return\n",
        "\n",
        "    if select_lora3.value != \"None\":\n",
        "      print('lora3')\n",
        "      try:\n",
        "          model.pipe.load_lora_weights(select_lora3.value)\n",
        "          model.pipe.fuse_lora(lora_scale=lora_weights_scale3.value)\n",
        "      except:\n",
        "          print(f\"ERROR: LoRA not compatible  {select_lora3.value}:\")\n",
        "          del model\n",
        "          generate.disabled = False\n",
        "          return\n",
        "\n",
        "    # Prompt Optimizations for 1.5\n",
        "    if os.path.exists(select_model.value):\n",
        "        if  active_ti.value:\n",
        "          # Textual Inversion\n",
        "          for name, directory_name in embed_list:\n",
        "\n",
        "              try:\n",
        "                      #model.pipe.text_encoder.resize_token_embeddings(len(model.pipe.tokenizer),pad_to_multiple_of=128)\n",
        "                      #model.pipe.load_textual_inversion(directory_name, token=name)\n",
        "                      #model.pipe.load_textual_inversion(\"./bad_prompt.pt\", token=\"baddd\")\n",
        "                      model.pipe.load_textual_inversion(directory_name, token=name)\n",
        "              except ValueError:\n",
        "                  #print('previous loaded ti')\n",
        "                  pass\n",
        "              except:\n",
        "                  print(f\"Can't apply {name}\")\n",
        "\n",
        "        #Prompt weights\n",
        "        global compel\n",
        "        compel = Compel(tokenizer=model.pipe.tokenizer, text_encoder=model.pipe.text_encoder, truncate_long_prompts=False)\n",
        "\n",
        "        prompt_ti = model.pipe.maybe_convert_prompt(prompt.value, model.pipe.tokenizer)\n",
        "        negative_prompt_ti = model.pipe.maybe_convert_prompt(neg_prompt.value, model.pipe.tokenizer)\n",
        "\n",
        "        if weights_prompt.value:\n",
        "            prompt_ti = prompt_weight_conversor(prompt_ti)\n",
        "            negative_prompt_ti = prompt_weight_conversor(negative_prompt_ti)\n",
        "\n",
        "        prompt_emb = merge_embeds(tokenize_line(prompt_ti, model.pipe.tokenizer))\n",
        "        negative_prompt_emb = merge_embeds(tokenize_line(negative_prompt_ti, model.pipe.tokenizer))\n",
        "\n",
        "        # fix error shape\n",
        "        if prompt_emb.shape != negative_prompt_emb.shape:\n",
        "            print('___')\n",
        "            #compel = Compel(tokenizer=model.pipe.tokenizer, text_encoder=model.pipe.text_encoder, truncate_long_prompts=False)\n",
        "            prompt_emb, negative_prompt_emb = compel.pad_conditioning_tensors_to_same_length([prompt_emb, negative_prompt_emb])\n",
        "            # prompt_emb = compel(prompt_ti)\n",
        "            # negative_prompt_emb = compel(negative_prompt_ti)\n",
        "\n",
        "        compel = None\n",
        "        del compel\n",
        "\n",
        "    model.pipe.enable_xformers_memory_efficient_attention()\n",
        "    model.pipe.scheduler = get_scheduler(select_sampler.value)\n",
        "    model.pipe.safety_checker = None\n",
        "\n",
        "    if options_controlnet.value != 'txt2img':\n",
        "        print(f'Control image: {destination_path_cn_img}')\n",
        "        image_pil = Image.open(destination_path_cn_img)\n",
        "        numpy_array = np.array(image_pil, dtype=np.uint8)\n",
        "        array_rgb = numpy_array[:, :, :3]\n",
        "\n",
        "\n",
        "    if not os.path.exists(select_model.value):\n",
        "        # SDXL\n",
        "        images = model.pipe(\n",
        "            prompt = prompt.value,\n",
        "            height = img_height.value,\n",
        "            width = img_width.value,\n",
        "            num_inference_steps = steps.value,\n",
        "            guidance_scale = CFG.value,\n",
        "            num_images_per_prompt = num_images.value,\n",
        "            negative_prompt = neg_prompt.value,\n",
        "            generator = torch.Generator(\"cuda\").manual_seed(seed),\n",
        "        ).images\n",
        "\n",
        "    elif options_controlnet.value == 'txt2img':\n",
        "\n",
        "        images = model.pipe(\n",
        "            # prompt = '', # prompt.value,\n",
        "            # negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            height = img_height.value,\n",
        "            width = img_width.value,\n",
        "            num_inference_steps = steps.value,\n",
        "            guidance_scale = CFG.value,\n",
        "            num_images_per_prompt = num_images.value,\n",
        "            generator = torch.Generator(\"cuda\").manual_seed(seed),\n",
        "        ).images\n",
        "\n",
        "    elif options_controlnet.value == 'Openpose':\n",
        "        print('BETA: Openpose, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_openpose(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['Openpose'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'Canny':\n",
        "        print('BETA: Canny')\n",
        "\n",
        "        images = model.process_canny(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            low_threshold=int_inputs['Canny'][0].value,\n",
        "            high_threshold=int_inputs['Canny'][1].value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'MLSD':\n",
        "        print('BETA: MLSD')\n",
        "\n",
        "        images = model.process_mlsd(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            value_threshold=int_inputs['MLSD'][0].value,\n",
        "            distance_threshold=int_inputs['MLSD'][1].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'scribble':\n",
        "        print('BETA: scribble, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_scribble(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['scribble'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'softedge':\n",
        "        print('BETA: softedge, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_softedge(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['softedge'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'segmentation':\n",
        "        print('BETA: segmentation, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_segmentation(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['segmentation'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'depth':\n",
        "        print('BETA: depth, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_depth(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['depth'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'NormalBae':\n",
        "        print('BETA: NormalBae, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_mlsd(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['NormalBae'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif 'lineart' in options_controlnet.value:\n",
        "        print('BETA: lineart, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_lineart(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['lineart'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'shuffle':\n",
        "        print('BETA: shuffle, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_shuffle(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['shuffle'][0].value,\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'ip2p':\n",
        "        print('BETA: (inpaint pix2pix) ip2p, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_ip2p(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        images = None\n",
        "\n",
        "    # if select_lora1.value != \"None\":\n",
        "    #     model.pipe.unfuse_lora()\n",
        "    #     model.pipe.unload_lora_weights()\n",
        "    # if select_lora2.value != \"None\" or select_lora3.value != \"None\":\n",
        "    #     print('BETA: reload weights for lora')\n",
        "    #     model.load_pipe(select_model.value, task_name=options_controlnet.value, vae_model = vae_model_dropdown.value, reload=True)\n",
        "    if select_lora1.value != \"None\":\n",
        "      model.pipe.load_lora_weights(select_lora1.value)\n",
        "      model.pipe.fuse_lora(lora_scale=-lora_weights_scale1.value)\n",
        "    if select_lora2.value != \"None\":\n",
        "      model.pipe.load_lora_weights(select_lora2.value)\n",
        "      model.pipe.fuse_lora(lora_scale=-lora_weights_scale2.value)\n",
        "    if select_lora3.value != \"None\":\n",
        "      model.pipe.load_lora_weights(select_lora3.value)\n",
        "      model.pipe.fuse_lora(lora_scale=-lora_weights_scale3.value)\n",
        "    # model.pipe.unfuse_lora()\n",
        "    # model.pipe.unload_lora_weights()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    mediapy.show_images(images)\n",
        "\n",
        "    # Save img\n",
        "    global image_list\n",
        "    image_list = []\n",
        "\n",
        "    metadata = [\n",
        "            prompt.value,\n",
        "            neg_prompt.value,\n",
        "            select_model.value,\n",
        "            vae_model_dropdown.value,\n",
        "            steps.value,\n",
        "            CFG.value,\n",
        "            select_sampler.value,\n",
        "            random_seed.value\n",
        "    ]\n",
        "\n",
        "    directory_images = './images'\n",
        "    os.makedirs(directory_images, exist_ok=True)\n",
        "\n",
        "    for image_ in images:\n",
        "        image_path = save_pil_image_with_metadata(image_, directory_images, metadata)\n",
        "        image_list.append(image_path)\n",
        "\n",
        "    print(f\"Seed:\\n{seed}\")\n",
        "\n",
        "  generate.disabled = False\n",
        "\n",
        "\n",
        "\n",
        "def elemets_textual_inversion(value):\n",
        "  with display_imgs:\n",
        "    print('Clearing output in 7 seconds')\n",
        "    print('The embeddings currently supported. Write in the prompt the word for use')\n",
        "    for name, directory_name in embed_list:\n",
        "\n",
        "        print(name)\n",
        "    time.sleep(7)\n",
        "    display_imgs.clear_output()\n",
        "\n",
        "#Display\n",
        "generate.on_click(generate_img)\n",
        "show_textual_inversion.on_click(elemets_textual_inversion)\n",
        "\n",
        "widgets.VBox(\n",
        "    [\n",
        "      widgets.AppLayout(\n",
        "        header=widgets.HTML(\n",
        "            value=\"<h1>Image Generated Interactive V2 [Vorst Cavry]</h1>\",\n",
        "        ),\n",
        "        left_sidebar=widgets.VBox(\n",
        "            [\n",
        "                num_images, steps,\n",
        "                CFG, select_sampler,\n",
        "                img_height, img_width,\n",
        "                random_seed,\n",
        "                select_lora1,\n",
        "                lora_weights_scale1,\n",
        "                select_lora2,\n",
        "                lora_weights_scale2,\n",
        "                select_lora3,\n",
        "                lora_weights_scale3,\n",
        "            ]\n",
        "        ),\n",
        "        center=widgets.VBox(\n",
        "            [\n",
        "                options_controlnet,\n",
        "                select_model,\n",
        "                vae_model_dropdown,\n",
        "                prompt,\n",
        "                neg_prompt,\n",
        "                show_textual_inversion,\n",
        "                active_ti,\n",
        "                weights_prompt,\n",
        "                generate,\n",
        "            ]\n",
        "        ),\n",
        "        right_sidebar=widgets.VBox(\n",
        "            [preprocess_resolution_global] + [int_input for int_inputs_list in int_inputs.values() for int_input in int_inputs_list]\n",
        "        ),\n",
        "        footer=None\n",
        "      ),\n",
        "      display_imgs\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Tf6cklfuRgJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload a Image here for use ControlNet ðŸ‘ˆâ€â€ ðŸ–¼ï¸ðŸ–¼ï¸ðŸ–¼ï¸\n",
        "#@markdown - To use Controlnet, you need to upload the control image with this cell\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "%cd /content\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = next(iter(uploaded))\n",
        "print(f'Uploaded file: {filename}')\n",
        "\n",
        "upload_folder = 'uploaded_controlnet_image/'\n",
        "if not os.path.exists(upload_folder):\n",
        "    os.makedirs(upload_folder)\n",
        "\n",
        "source_path = filename\n",
        "destination_path_cn_img = os.path.join(upload_folder, filename)\n",
        "shutil.move(source_path, destination_path_cn_img)\n",
        "print(f'Moved file to {destination_path_cn_img}')"
      ],
      "metadata": {
        "id": "HIUB-L5MsQw1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ‘‡ Upscale and face restoration { form-width: \"20%\", display-mode: \"form\" }\n",
        "from IPython.utils import capture\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "%cd /content\n",
        "directory_codeformer = '/content/CodeFormer/'\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists(directory_codeformer):\n",
        "      os.makedirs(directory_codeformer)\n",
        "\n",
        "      # Setup\n",
        "      # Clone CodeFormer and enter the CodeFormer folder\n",
        "      %cd /content\n",
        "      !git clone https://github.com/sczhou/CodeFormer.git\n",
        "      %cd CodeFormer\n",
        "\n",
        "\n",
        "      # Set up the environment\n",
        "      # Install python dependencies\n",
        "      !pip install -q -r requirements.txt\n",
        "      !pip -q install ffmpeg\n",
        "      # Install basicsr\n",
        "      !python basicsr/setup.py develop\n",
        "\n",
        "      # Download the pre-trained model\n",
        "      !python scripts/download_pretrained_models.py facelib\n",
        "      !python scripts/download_pretrained_models.py CodeFormer\n",
        "  del cap\n",
        "# Visualization function\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('CodeFormer', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# Copy imgs\n",
        "destination_directory = '/content/CodeFormer/inputs/user_upload'\n",
        "!rm -rf /content/CodeFormer/inputs/user_upload/*\n",
        "os.makedirs(destination_directory, exist_ok=True)\n",
        "for image_path in image_list:\n",
        "    image_filename = os.path.basename('/content/'+image_path)\n",
        "    destination_path = os.path.join(destination_directory, image_filename)\n",
        "    try:\n",
        "        shutil.copyfile('/content/'+image_path, destination_path)\n",
        "        print(f\"Image '{image_filename}' has been copied to '{destination_path}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to copy '{image_filename}' to '{destination_path}': {e}\")\n",
        "\n",
        "#@markdown `CODEFORMER_FIDELITY`: Balance the quality (lower number) and fidelity (higher number)<br>\n",
        "# you can add '--bg_upsampler realesrgan' to enhance the background\n",
        "CODEFORMER_FIDELITY = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown `BACKGROUND_ENHANCE`: Enhance background image with Real-ESRGAN<br>\n",
        "BACKGROUND_ENHANCE = True #@param {type:\"boolean\"}\n",
        "#@markdown `FACE_UPSAMPLE`: Upsample restored faces for high-resolution AI-created images<br>\n",
        "FACE_UPSAMPLE = False #@param {type:\"boolean\"}\n",
        "#markdown `HAS_ALIGNED`: Input are cropped and aligned faces<br>\n",
        "HAS_ALIGNED =  False\n",
        "#@markdown `UPSCALE`: The final upsampling scale of the image. Default: 2<br>\n",
        "UPSCALE = 3 #@param {type:\"slider\", min:2, max:8, step:1}\n",
        "#markdown `DETECTION_MODEL`: Face detector. Default: retinaface_resnet50<br>\n",
        "DETECTION_MODEL = \"retinaface_resnet50\"\n",
        "#markdown `DRAW_BOX`: Draw the bounding box for the detected faces.\n",
        "DRAW_BOX = False\n",
        "\n",
        "BACKGROUND_ENHANCE = '--bg_upsampler realesrgan' if BACKGROUND_ENHANCE else ''\n",
        "FACE_UPSAMPLE = '--face_upsample' if FACE_UPSAMPLE else ''\n",
        "HAS_ALIGNED = '--has_aligned' if HAS_ALIGNED else ''\n",
        "DRAW_BOX = '--draw_box' if DRAW_BOX else ''\n",
        "%cd CodeFormer\n",
        "!python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path {destination_directory} {BACKGROUND_ENHANCE} {FACE_UPSAMPLE} {HAS_ALIGNED} --upscale {UPSCALE} --detection_model {DETECTION_MODEL} {DRAW_BOX}\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs/user_upload'\n",
        "result_folder = f'results/user_upload_{CODEFORMER_FIDELITY}/final_results'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "for input_path in input_list:\n",
        "  img_input = imread(input_path)\n",
        "  basename = os.path.splitext(os.path.basename(input_path))[0]\n",
        "  output_path = os.path.join(result_folder, basename+'.png')\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "__21H6ZLUokz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Images\n",
        "import os\n",
        "from google.colab import files\n",
        "!rm /content/results.zip\n",
        "!ls /content/images\n",
        "print('Download results')\n",
        "os.system(f'zip -r results.zip /content/images')\n",
        "try:\n",
        "  files.download(\"results.zip\")\n",
        "except:\n",
        "  print(\"Error\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Wlmke1VJPWS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Upscale results\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "%cd /content/CodeFormer\n",
        "!ls results\n",
        "print('Download results')\n",
        "os.system(f'zip -r results.zip results/user_upload_{CODEFORMER_FIDELITY}/final_results')\n",
        "try:\n",
        "  files.download(\"results.zip\")\n",
        "except:\n",
        "  files.download(f'/content/CodeFormer/results/{filename[:-4]}_{CODEFORMER_FIDELITY}/{filename}')\n",
        "%cd /content"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k-FPYmh2Wb4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also use this cell to simply reload the model in case you need to.\n",
        "del model"
      ],
      "metadata": {
        "id": "JHxjQLbQ--O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTMQQIjNA6m3"
      },
      "source": [
        "#bagaian bawah ini adalah project beta, jika ada yang berminat membantu silahkan saja"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ‘‡ Generating Images âŒKOLOM INI MASIH MENGALAMI EROR PADA LORAâŒ\n",
        "\n",
        "\n",
        "#@markdown **[IND]**\n",
        "#@markdown ---\n",
        "#@markdown - **Prompt** - Deskripsi gambar\n",
        "#@markdown - **Prompt Negatif** - Hal-hal yang tidak ingin Anda lihat atau abaikan dalam gambar\n",
        "#@markdown - **Langkah** - Jumlah langkah denoising. Langkah yang lebih tinggi dapat menghasilkan hasil yang lebih baik tetapi membutuhkan waktu lebih lama untuk menghasilkan gambar. Standarnya adalah `30`.\n",
        "#@markdown - **CFG** - Skala panduan mulai dari `0` hingga `20`. Nilai yang lebih rendah memungkinkan AI menjadi lebih kreatif dan tidak terlalu ketat dalam mengikuti perintah. Nilai default adalah `7,5`.\n",
        "#@markdown - **Sampler** - Penjadwal bertanggung jawab untuk mengontrol laju pembelajaran model difusi. Penjadwal yang berbeda dapat menghasilkan hasil yang berbeda, jadi penting untuk memilih penjadwal yang sesuai untuk tugas yang diinginkan.\n",
        "#@markdown - **Seed** - Nilai acak yang mengontrol pembuatan gambar. Seed dan prompt yang sama akan menghasilkan gambar yang sama. Tetapkan `-1` untuk menggunakan nilai seed acak.\n",
        "#@markdown - **Bobot prompt** - Merupakan cara untuk mengontrol pengaruh prompt teks yang berbeda pada proses pembuatan gambar. Prompt weights dapat digunakan untuk menekankan atau menghilangkan penekanan pada aspek tertentu gambar, misalnya, objek, pemandangan, atau gaya. Saat ini, sintaks [Compel syntax](https://github.com/damian0815/compel/blob/main/doc/syntax.md) sedang digunakan. Anda juga dapat mengaktifkan `Convert Prompt weights` untuk secara otomatis mengonversi sintaks dari `(word:1.1)` ke `(word)1.1` atau `(word)` ke `(word)+` agar kompatibel dengan bobot Compel. Compel menskalakan lebih banyak dengan nilai-nilainya sehingga lebih sedikit bobot yang diperlukan untuk hasil yang baik\n",
        "#@markdown - **ControlNet** - Adalah model jaringan saraf untuk mengendalikan model difusi. Ini memungkinkan pengguna untuk memasukkan informasi tambahan, seperti peta tepi, peta segmentasi, dan titik-titik kunci, ke dalam model difusi untuk memandu proses pembuatan gambar.\n",
        "#@markdown ---\n",
        "#@markdown **[ENG]**\n",
        "#@markdown ---\n",
        "#@markdown - **Prompt** - Description of the image\n",
        "#@markdown - **Negative Prompt** - Things you don't want to see or ignore in the image\n",
        "#@markdown - **Steps** - Number of denoising steps. Higher steps may lead to better results but takes longer time to generate the image. Default is `30`.\n",
        "#@markdown - **CFG** - Guidance scale ranging from `0` to `20`. Lower values allow the AI to be more creative and less strict at following the prompt. Default is `7.5`.\n",
        "#@markdown - **Sampler** - The scheduler is responsible for controlling the learning rate of the diffusion model. Different schedulers can produce different results, so it is important to choose a scheduler that is appropriate for the desired task.\n",
        "#@markdown - **Seed** - A random value that controls image generation. The same seed and prompt produce the same images. Set `-1` for using random seed values.\n",
        "#@markdown - **Prompt weights** -  Are a way to control the influence of different text prompts on the image generation process. Prompt weights can be used to emphasize or de-emphasize certain aspects of the image, such as the object, the scene, or the style. Currently, the [Compel syntax](https://github.com/damian0815/compel/blob/main/doc/syntax.md) is being used. You can also activate the `Convert Prompt weights` to automatically convert syntax from `(word:1.1)` to `(word)1.1` or `(word)` to `(word)+` to make them compatible with Compel weights. Compel scale more with its values so that fewer weights are needed for good results\n",
        "#@markdown - **ControlNet** - Is a neural network model for controlling diffusion models. It allows users to input additional information, such as edge maps, segmentation maps, and key points, into diffusion models to guide the image generation process.\n",
        "#@markdown ---\n",
        "%cd /content\n",
        "import ipywidgets as widgets, mediapy, random\n",
        "from diffusers.models.attention_processor import AttnProcessor2_0\n",
        "from PIL import Image\n",
        "import IPython.display\n",
        "from diffusers import (\n",
        "    DPMSolverMultistepScheduler,\n",
        "    DPMSolverSinglestepScheduler,\n",
        "    KDPM2DiscreteScheduler,\n",
        "    KDPM2AncestralDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    HeunDiscreteScheduler,\n",
        "    LMSDiscreteScheduler,\n",
        "    DDIMScheduler,\n",
        "    DiffusionPipeline,\n",
        ")\n",
        "import time\n",
        "from IPython.utils import capture\n",
        "import logging\n",
        "logging.getLogger(\"diffusers\").setLevel(logging.ERROR)\n",
        "\n",
        "#from IPython.display import display\n",
        "from ipywidgets import interactive, Layout, VBox\n",
        "\n",
        "#Get scheduler\n",
        "def get_scheduler(name):\n",
        "\n",
        "  match name:\n",
        "\n",
        "    case \"DPM++ 2M\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config)\n",
        "\n",
        "    case \"DPM++ 2M Karras\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"DPM++ 2M SDE\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config, algorithm_type=\"sde-dpmsolver++\")\n",
        "\n",
        "    case \"DPM++ 2M SDE Karras\":\n",
        "      return DPMSolverMultistepScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True, algorithm_type=\"sde-dpmsolver++\")\n",
        "\n",
        "    case \"DPM++ SDE\":\n",
        "      return DPMSolverSinglestepScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"DPM++ SDE Karras\":\n",
        "      return DPMSolverSinglestepScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"DPM2\":\n",
        "      return KDPM2DiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"DPM2 Karras\":\n",
        "      return KDPM2DiscreteScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"Euler\":\n",
        "      return EulerDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"Euler a\":\n",
        "      return EulerAncestralDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"Heun\":\n",
        "      return HeunDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"LMS\":\n",
        "      return LMSDiscreteScheduler.from_config(model.pipe.scheduler.config, )\n",
        "\n",
        "    case \"LMS Karras\":\n",
        "      return LMSDiscreteScheduler.from_config(model.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "\n",
        "    case \"DDIMScheduler\":\n",
        "      return DDIMScheduler.from_config(model.pipe.scheduler.config)\n",
        "\n",
        "#PARAMETER WIDGETS\n",
        "width = \"250px\"\n",
        "\n",
        "select_model = widgets.Dropdown(\n",
        "    options=model_list,\n",
        "    description=\"Model:\"\n",
        ")\n",
        "\n",
        "vae_model_dropdown = widgets.Dropdown(\n",
        "    options=vae_model_list,\n",
        "    description=\"VAE:\"\n",
        ")\n",
        "\n",
        "prompt = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter prompt\",\n",
        "    #description=\"Prompt:\",\n",
        "    rows=5,\n",
        "    layout=widgets.Layout(width=\"550px\")\n",
        ")\n",
        "\n",
        "neg_prompt = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter negative prompt\",\n",
        "    #description=\"Negative Prompt:\",\n",
        "    rows=5,\n",
        "    layout=widgets.Layout(width=\"550px\")\n",
        ")\n",
        "\n",
        "num_images = widgets.IntText(\n",
        "    value=1,\n",
        "    description=\"Images:\",\n",
        "    layout=widgets.Layout(width=width),\n",
        ")\n",
        "\n",
        "steps = widgets.IntText(\n",
        "    value=30,\n",
        "    description=\"Steps:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "CFG = widgets.FloatText(\n",
        "    value=7.5,\n",
        "    step=0.5,\n",
        "    description=\"CFG:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "select_sampler = widgets.Dropdown(\n",
        "    options=[\n",
        "        \"DPM++ 2M\",\n",
        "        \"DPM++ 2M Karras\",\n",
        "        \"DPM++ 2M SDE\",\n",
        "        \"DPM++ 2M SDE Karras\",\n",
        "        \"DPM++ SDE\",\n",
        "        \"DPM++ SDE Karras\",\n",
        "        \"DPM2\",\n",
        "        \"DPM2 Karras\",\n",
        "        \"Euler\",\n",
        "        \"Euler a\",\n",
        "        \"Heun\",\n",
        "        \"LMS\",\n",
        "        \"LMS Karras\",\n",
        "        \"DDIMScheduler\",\n",
        "    ],\n",
        "    description=\"Scheduler:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "#select_sampler.style.description_width = \"auto\"\n",
        "\n",
        "img_height = widgets.IntText(\n",
        "    min=256,\n",
        "    max=2048,\n",
        "    value=512,\n",
        "    description=\"Height:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "img_width = widgets.IntText(\n",
        "    min=256,\n",
        "    max=2048,\n",
        "    value=512,\n",
        "    description=\"Width:\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "\n",
        "random_seed = widgets.IntText(\n",
        "    value=-1,\n",
        "    description=\"Seed:\",\n",
        "    layout=widgets.Layout(width=width),\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "generate = widgets.Button(\n",
        "    description=\"Generate\",\n",
        "    disabled=False,\n",
        "    button_style=\"primary\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "# textual inversion\n",
        "show_textual_inversion = widgets.Button(\n",
        "    description=\"List available textual inversions\",\n",
        "    disabled=False,\n",
        "    button_style=\"info\",\n",
        "    layout=widgets.Layout(width=width)\n",
        ")\n",
        "active_ti = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Active Textual Inversion in prompt (Experimental)',\n",
        ")\n",
        "# alternative prompt weights\n",
        "weights_prompt = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Convert Prompt weights',\n",
        ")\n",
        "\n",
        "#lora1\n",
        "select_lora1 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora1:\",\n",
        "    layout={'width':'190px'}\n",
        ")\n",
        "\n",
        "lora_weights_scale1 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    #description=\"Lora scale1:\",\n",
        "    layout={'width':'56px'}\n",
        ")\n",
        "#lora2\n",
        "select_lora2 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora2:\",\n",
        "    layout={'width':'190px'}\n",
        ")\n",
        "\n",
        "lora_weights_scale2 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    #description=\"Lora scale2:\",\n",
        "    layout={'width':'56px'}\n",
        ")\n",
        "#lora3\n",
        "select_lora3 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora3:\",\n",
        "    layout={'width':'190px'}\n",
        ")\n",
        "\n",
        "lora_weights_scale3 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    #description=\"Lora scale3:\",\n",
        "    layout={'width':'56px'}\n",
        ")\n",
        "#lora4\n",
        "select_lora4 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora4:\",\n",
        "    layout={'width':'190px'}\n",
        ")\n",
        "\n",
        "lora_weights_scale4 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    #description=\"Lora scale4:\",\n",
        "    layout={'width':'56px'}\n",
        ")\n",
        "#lora5\n",
        "select_lora5 = widgets.Dropdown(\n",
        "    options=lora_model_list,\n",
        "    description=\"Lora5:\",\n",
        "    layout={'width':'190px'}\n",
        ")\n",
        "\n",
        "lora_weights_scale5 = widgets.FloatText(\n",
        "    min=-2.0,\n",
        "    max=2.0,\n",
        "    step=0.01,\n",
        "    value=1,\n",
        "    #description=\"Lora scale5:\",\n",
        "    layout={'width':'56px'}\n",
        ")\n",
        "\n",
        "display_imgs = widgets.Output()\n",
        "\n",
        "\n",
        "### second part ####\n",
        "preprocess_resolution_global = widgets.IntSlider(\n",
        "    value=512,\n",
        "    min=256,\n",
        "    max=2048,\n",
        "    description='Preprocess resolution ControlNet'\n",
        ")\n",
        "\n",
        "control_model_list = list(CONTROLNET_MODEL_IDS.keys())\n",
        "\n",
        "# Create a Dropdown for selecting options\n",
        "options_controlnet = widgets.Dropdown(\n",
        "    options=[\n",
        "        control_model_list[13],\n",
        "        control_model_list[12],\n",
        "        control_model_list[0],\n",
        "        control_model_list[1],\n",
        "        control_model_list[2],\n",
        "        control_model_list[3],\n",
        "        control_model_list[4],\n",
        "        control_model_list[5],\n",
        "        control_model_list[6],\n",
        "        control_model_list[7],\n",
        "        control_model_list[8],\n",
        "        control_model_list[10],\n",
        "        control_model_list[11],\n",
        "    ],\n",
        "    description='TASK:',\n",
        "    layout=widgets.Layout(width=\"550px\"),\n",
        ")\n",
        "\n",
        "neg_prompt = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enter negative prompt\",\n",
        "    #description=\"Negative Prompt:\",\n",
        "    rows=5,\n",
        "    layout=widgets.Layout(width=\"550px\")\n",
        ")\n",
        "# Create a dictionary to map options to lists of IntText widgets\n",
        "int_inputs = {\n",
        "\n",
        "    control_model_list[13]: [\n",
        "    ],\n",
        "    control_model_list[12]: [\n",
        "        widgets.FloatSlider(value=1.0, min=0.01, max=1.0, step=0.01, description='Inpaint strength:', layout=Layout(visibility='hidden')),\n",
        "        widgets.Textarea(value=\"\", placeholder=\"/content/my_mask.png\", rows=1, description='Mask path:', layout=Layout(visibility='hidden'))\n",
        "    ],\n",
        "    control_model_list[0]: [\n",
        "        widgets.Dropdown(value='Openpose', description='Preprocessor:', options=['None','Openpose'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[1]: [\n",
        "        widgets.IntText(value=100, min=1, max=255, description='Canny low threshold:', layout=Layout(visibility='hidden')),\n",
        "        widgets.IntText(value=200, min=1, max=255, description='Canny high threshold:', layout=Layout(visibility='hidden'))\n",
        "    ],\n",
        "    control_model_list[2]: [\n",
        "        widgets.FloatText(value=0.1, min=1, max=2.0, description='Hough value threshold (MLSD):', layout=Layout(visibility='hidden')),\n",
        "        widgets.FloatText(value=0.1, min=1, max=20.0, description='Hough distance threshold (MLSD):', layout=Layout(visibility='hidden'))\n",
        "    ],\n",
        "    control_model_list[3]: [\n",
        "        widgets.Dropdown(value='HED', description='Preprocessor:', options=['HED','PidiNet', 'None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[4]: [\n",
        "        widgets.Dropdown(value='PidiNet', description='Preprocessor:', options=['HED','PidiNet', 'HED safe', 'PidiNet safe','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[5]: [\n",
        "        widgets.Dropdown(value='UPerNet', description='Preprocessor:', options=['UPerNet','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[6]: [\n",
        "        widgets.Dropdown(value='DPT', description='Preprocessor:', options=['Midas', 'DPT','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[7]: [\n",
        "        widgets.Dropdown(value='NormalBae', description='Preprocessor:', options=['NormalBae','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[8]: [\n",
        "        widgets.Dropdown(value='Lineart', description='Preprocessor:', options=['Lineart','Lineart coarse', 'None', 'Lineart (anime)', 'None (anime)'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "    control_model_list[10]: [\n",
        "        widgets.Dropdown(value='ContentShuffle', description='Preprocessor:', options=['ContentShuffle','None'], layout=Layout(visibility='hidden')),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Function to update visibility and enable/disable state of widgets\n",
        "def update_widgets(option):\n",
        "    for opt, int_inputs_list in int_inputs.items():\n",
        "        if opt == option:\n",
        "            for int_input in int_inputs_list:\n",
        "                int_input.layout.visibility = 'visible'\n",
        "        else:\n",
        "            for int_input in int_inputs_list:\n",
        "                int_input.layout.visibility = 'hidden'\n",
        "\n",
        "interactive(update_widgets, option=options_controlnet)\n",
        "\n",
        "### GENERATE ###\n",
        "\n",
        "def generate_img(i):\n",
        "  global model\n",
        "  #Clear output\n",
        "  display_imgs.clear_output()\n",
        "  generate.disabled = True\n",
        "\n",
        "  #Calculate seed\n",
        "  seed = random.randint(0, 2147483647) if random_seed.value == -1 else random_seed.value\n",
        "\n",
        "  with display_imgs:\n",
        "\n",
        "    print(\"Running...\")\n",
        "\n",
        "\n",
        "    # First load\n",
        "    try:\n",
        "        model\n",
        "    except:\n",
        "        model = Model(base_model_id=select_model.value, task_name=options_controlnet.value, vae_model = vae_model_dropdown.value)\n",
        "\n",
        "    model.load_pipe(select_model.value, task_name=options_controlnet.value, vae_model = vae_model_dropdown.value)\n",
        "\n",
        "    display_imgs.clear_output()\n",
        "\n",
        "    model.pipe.to(\"cuda\")\n",
        "    # model.pipe.unfuse_lora()\n",
        "    # model.pipe.unload_lora_weights()\n",
        "\n",
        "    if select_lora1.value != \"None\":\n",
        "      print('lora1')\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora1.value, lora_weights_scale1.value)\n",
        "      except:\n",
        "          print(f\"ERROR: LoRA not compatible:  {select_lora1.value}\")\n",
        "    if select_lora2.value != \"None\":\n",
        "      print('lora2')\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora2.value, lora_weights_scale2.value)\n",
        "      except:\n",
        "          print(f\"ERROR: LoRA not compatible:  {select_lora2.value}\")\n",
        "\n",
        "    if select_lora3.value != \"None\":\n",
        "      print('lora3')\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora3.value, lora_weights_scale3.value)\n",
        "      except:\n",
        "          print(f\"ERROR: LoRA not compatible:  {select_lora3.value}\")\n",
        "    model.pipe.to(\"cuda\")\n",
        "\n",
        "    if select_lora4.value != \"None\":\n",
        "      print('lora4')\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora4.value, lora_weights_scale4.value)\n",
        "      except:\n",
        "          print(f\"ERROR: LoRA not compatible:  {select_lora4.value}\")\n",
        "\n",
        "    if select_lora5.value != \"None\":\n",
        "      print('lora5')\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora5.value, lora_weights_scale5.value)\n",
        "      except:\n",
        "          print(f\"ERROR: LoRA not compatible:  {select_lora5.value}\")\n",
        "\n",
        "    model.pipe.to(\"cuda\")\n",
        "\n",
        "    # Prompt Optimizations for 1.5\n",
        "    if os.path.exists(select_model.value):\n",
        "        if  active_ti.value:\n",
        "          # Textual Inversion\n",
        "          for name, directory_name in embed_list:\n",
        "\n",
        "              try:\n",
        "                      #model.pipe.text_encoder.resize_token_embeddings(len(model.pipe.tokenizer),pad_to_multiple_of=128)\n",
        "                      #model.pipe.load_textual_inversion(directory_name, token=name)\n",
        "                      #model.pipe.load_textual_inversion(\"./bad_prompt.pt\", token=\"baddd\")\n",
        "                      model.pipe.load_textual_inversion(directory_name, token=name)\n",
        "              except ValueError:\n",
        "                  #print('previous loaded ti')\n",
        "                  pass\n",
        "              except:\n",
        "                  print(f\"Can't apply {name}\")\n",
        "\n",
        "        #Prompt weights\n",
        "        global compel\n",
        "        compel = Compel(tokenizer=model.pipe.tokenizer, text_encoder=model.pipe.text_encoder, truncate_long_prompts=False)\n",
        "\n",
        "        prompt_ti = model.pipe.maybe_convert_prompt(prompt.value, model.pipe.tokenizer)\n",
        "        negative_prompt_ti = model.pipe.maybe_convert_prompt(neg_prompt.value, model.pipe.tokenizer)\n",
        "\n",
        "        if weights_prompt.value:\n",
        "            prompt_ti = prompt_weight_conversor(prompt_ti)\n",
        "            negative_prompt_ti = prompt_weight_conversor(negative_prompt_ti)\n",
        "\n",
        "        prompt_emb = merge_embeds(tokenize_line(prompt_ti, model.pipe.tokenizer))\n",
        "        negative_prompt_emb = merge_embeds(tokenize_line(negative_prompt_ti, model.pipe.tokenizer))\n",
        "\n",
        "        # fix error shape\n",
        "        if prompt_emb.shape != negative_prompt_emb.shape:\n",
        "            print('___')\n",
        "            #compel = Compel(tokenizer=model.pipe.tokenizer, text_encoder=model.pipe.text_encoder, truncate_long_prompts=False)\n",
        "            prompt_emb, negative_prompt_emb = compel.pad_conditioning_tensors_to_same_length([prompt_emb, negative_prompt_emb])\n",
        "            # prompt_emb = compel(prompt_ti)\n",
        "            # negative_prompt_emb = compel(negative_prompt_ti)\n",
        "\n",
        "        compel = None\n",
        "        del compel\n",
        "\n",
        "    model.pipe.enable_xformers_memory_efficient_attention()\n",
        "    model.pipe.scheduler = get_scheduler(select_sampler.value)\n",
        "    model.pipe.safety_checker = None\n",
        "\n",
        "    if options_controlnet.value != 'txt2img':\n",
        "        try:\n",
        "            print(f'Control image: {destination_path_cn_img}')\n",
        "            image_pil = Image.open(destination_path_cn_img)\n",
        "            numpy_array = np.array(image_pil, dtype=np.uint8)\n",
        "            array_rgb = numpy_array[:, :, :3]\n",
        "        except:\n",
        "            print(\"To use this function, you have to upload an image in the cell below first ðŸ‘‡\")\n",
        "            del model\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            generate.disabled = False\n",
        "            return\n",
        "\n",
        "\n",
        "    if not os.path.exists(select_model.value):\n",
        "        # SDXL\n",
        "        images = model.pipe(\n",
        "            prompt = prompt.value,\n",
        "            height = img_height.value,\n",
        "            width = img_width.value,\n",
        "            num_inference_steps = steps.value,\n",
        "            guidance_scale = CFG.value,\n",
        "            num_images_per_prompt = num_images.value,\n",
        "            negative_prompt = neg_prompt.value,\n",
        "            generator = torch.Generator(\"cuda\").manual_seed(seed),\n",
        "        ).images\n",
        "\n",
        "    elif options_controlnet.value == 'txt2img':\n",
        "\n",
        "        images = model.pipe(\n",
        "            # prompt = '', # prompt.value,\n",
        "            # negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            height = img_height.value,\n",
        "            width = img_width.value,\n",
        "            num_inference_steps = steps.value,\n",
        "            guidance_scale = CFG.value,\n",
        "            num_images_per_prompt = num_images.value,\n",
        "            generator = torch.Generator(\"cuda\").manual_seed(seed),\n",
        "        ).images\n",
        "\n",
        "    elif options_controlnet.value == 'Inpaint':\n",
        "        global mask_control\n",
        "        init_image = destination_path_cn_img\n",
        "        name_without_extension = os.path.splitext(init_image.split('/')[-1])[0]\n",
        "\n",
        "        image64 = base64.b64encode(open(init_image, 'rb').read())\n",
        "        image64 = image64.decode('utf-8')\n",
        "\n",
        "        img = np.array(plt.imread(f'{init_image}')[:,:,:3])\n",
        "\n",
        "        if os.path.exists(int_inputs['Inpaint'][1].value):\n",
        "            mask_control = int_inputs['Inpaint'][1].value\n",
        "\n",
        "        mask_control_img = Image.open(mask_control)\n",
        "        numpy_array_mask = np.array(mask_control_img, dtype=np.uint8)\n",
        "        array_rgb_mask = numpy_array_mask[:, :, :3]\n",
        "\n",
        "        # else:\n",
        "        #     draw(image64, filename=f\"./{name_without_extension}_draw.png\", w=img.shape[1], h=img.shape[0], line_width=0.04*img.shape[1])\n",
        "\n",
        "        #     with_mask = np.array(plt.imread(f\"./{name_without_extension}_draw.png\")[:,:,:3])\n",
        "        #     mask = (with_mask[:,:,0]==1)*(with_mask[:,:,1]==0)*(with_mask[:,:,2]==0)\n",
        "        #     plt.imsave(f\"./{name_without_extension}_mask.png\",mask, cmap='gray')\n",
        "        #     mask_control = f\"./{name_without_extension}_mask.png\"\n",
        "        #     print(f'Mask saved: {mask_control}')\n",
        "\n",
        "        images = model.process_inpaint(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value), ### edit\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocess_resolution=preprocess_resolution_global.value, # edit size in Inpaint\n",
        "            image_mask=array_rgb_mask,\n",
        "            strength=int_inputs['Inpaint'][0].value,\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'Openpose':\n",
        "        print('BETA: Openpose, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_openpose(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['Openpose'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'Canny':\n",
        "        print('BETA: Canny')\n",
        "\n",
        "        images = model.process_canny(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            low_threshold=int_inputs['Canny'][0].value,\n",
        "            high_threshold=int_inputs['Canny'][1].value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'MLSD':\n",
        "        print('BETA: MLSD')\n",
        "\n",
        "        images = model.process_mlsd(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            value_threshold=int_inputs['MLSD'][0].value,\n",
        "            distance_threshold=int_inputs['MLSD'][1].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'scribble':\n",
        "        print('BETA: scribble, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_scribble(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['scribble'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'softedge':\n",
        "        print('BETA: softedge, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_softedge(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['softedge'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'segmentation':\n",
        "        print('BETA: segmentation, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_segmentation(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['segmentation'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'depth':\n",
        "        print('BETA: depth, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_depth(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['depth'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'NormalBae':\n",
        "        print('BETA: NormalBae, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_mlsd(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['NormalBae'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif 'lineart' in options_controlnet.value:\n",
        "        print('BETA: lineart, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_lineart(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['lineart'][0].value,\n",
        "            preprocess_resolution=preprocess_resolution_global.value\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'shuffle':\n",
        "        print('BETA: shuffle, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_shuffle(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "            preprocessor_name=int_inputs['shuffle'][0].value,\n",
        "        )\n",
        "\n",
        "    elif options_controlnet.value == 'ip2p':\n",
        "        print('BETA: (inpaint pix2pix) ip2p, resolution min(W, H)')\n",
        "\n",
        "        images = model.process_ip2p(\n",
        "            image=array_rgb,\n",
        "            prompt='', # prompt.value,\n",
        "            negative_prompt = '', # negative_prompt = neg_prompt.value,\n",
        "            prompt_embeds=prompt_emb,\n",
        "            negative_prompt_embeds=negative_prompt_emb,\n",
        "            additional_prompt=\"\",\n",
        "            num_images=num_images.value,\n",
        "            image_resolution=min(img_height.value, img_width.value),\n",
        "            num_steps=steps.value,\n",
        "            guidance_scale=CFG.value,\n",
        "            seed=seed,\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        images = None\n",
        "\n",
        "    # if select_lora1.value != \"None\":\n",
        "    #     model.pipe.unfuse_lora()\n",
        "    #     model.pipe.unload_lora_weights()\n",
        "    # if select_lora2.value != \"None\" or select_lora3.value != \"None\":\n",
        "    #     print('BETA: reload weights for lora')\n",
        "    #     model.load_pipe(select_model.value, task_name=options_controlnet.value, vae_model = vae_model_dropdown.value, reload=True)\n",
        "    if select_lora1.value != \"None\":\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora1.value, -lora_weights_scale1.value)\n",
        "      except:\n",
        "          pass\n",
        "    if select_lora2.value != \"None\":\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora2.value, -lora_weights_scale2.value)\n",
        "      except:\n",
        "          pass\n",
        "    if select_lora3.value != \"None\":\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora3.value, -lora_weights_scale3.value)\n",
        "      except:\n",
        "          pass\n",
        "    if select_lora4.value != \"None\":\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora4.value, -lora_weights_scale4.value)\n",
        "      except:\n",
        "          pass\n",
        "    if select_lora5.value != \"None\":\n",
        "      try:\n",
        "          model.pipe = lora_mix_load(model.pipe, select_lora5.value, -lora_weights_scale5.value)\n",
        "      except:\n",
        "          pass\n",
        "    # model.pipe.unfuse_lora()\n",
        "    # model.pipe.unload_lora_weights()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    mediapy.show_images(images)\n",
        "\n",
        "    # Save img\n",
        "    global image_list\n",
        "    image_list = []\n",
        "\n",
        "    metadata = [\n",
        "            prompt.value,\n",
        "            neg_prompt.value,\n",
        "            select_model.value,\n",
        "            vae_model_dropdown.value,\n",
        "            steps.value,\n",
        "            CFG.value,\n",
        "            select_sampler.value,\n",
        "            random_seed.value\n",
        "    ]\n",
        "\n",
        "    directory_images = './images'\n",
        "    os.makedirs(directory_images, exist_ok=True)\n",
        "\n",
        "    for image_ in images:\n",
        "        image_path = save_pil_image_with_metadata(image_, directory_images, metadata)\n",
        "        image_list.append(image_path)\n",
        "\n",
        "    print(f\"Seed:\\n{seed}\")\n",
        "\n",
        "  generate.disabled = False\n",
        "\n",
        "\n",
        "\n",
        "def elemets_textual_inversion(value):\n",
        "  with display_imgs:\n",
        "    print('Clearing output in 7 seconds')\n",
        "    print('The embeddings currently supported. Write in the prompt the word for use')\n",
        "    for name, directory_name in embed_list:\n",
        "\n",
        "        print(name)\n",
        "    time.sleep(7)\n",
        "    display_imgs.clear_output()\n",
        "\n",
        "\n",
        "generate.on_click(generate_img)\n",
        "show_textual_inversion.on_click(elemets_textual_inversion)\n",
        "\n",
        "# TABS\n",
        "tab = widgets.Tab()\n",
        "\n",
        "#Display\n",
        "\n",
        "# TAB 1\n",
        "tab_sd = widgets.VBox(\n",
        "    [\n",
        "      widgets.AppLayout(\n",
        "        header=None,\n",
        "        left_sidebar=widgets.VBox(\n",
        "            [\n",
        "                num_images, steps,\n",
        "                CFG, select_sampler,\n",
        "                img_height, img_width,\n",
        "                random_seed,\n",
        "                widgets.HBox([select_lora1, lora_weights_scale1]),\n",
        "                widgets.HBox([select_lora2, lora_weights_scale2]),\n",
        "                widgets.HBox([select_lora3, lora_weights_scale3]),\n",
        "                widgets.HBox([select_lora4, lora_weights_scale4]),\n",
        "                widgets.HBox([select_lora5, lora_weights_scale5]),\n",
        "            ]\n",
        "        ),\n",
        "        center=widgets.VBox(\n",
        "            [\n",
        "                widgets.HTML(\n",
        "                    value=\"<h2>SD Interactive</h2>\",\n",
        "                    layout=widgets.Layout(display=\"flex\", justify_content=\"center\")\n",
        "                ),\n",
        "                options_controlnet,\n",
        "                select_model,\n",
        "                vae_model_dropdown,\n",
        "                prompt,\n",
        "                neg_prompt,\n",
        "                show_textual_inversion,\n",
        "                active_ti,\n",
        "                weights_prompt,\n",
        "                generate,\n",
        "            ]\n",
        "        ),\n",
        "        right_sidebar=widgets.VBox(\n",
        "            [preprocess_resolution_global] + [int_input for int_inputs_list in int_inputs.values() for int_input in int_inputs_list]\n",
        "        ),\n",
        "        footer=None\n",
        "      ),\n",
        "      display_imgs,\n",
        "    ]\n",
        ")\n",
        "\n",
        "# TAB 2\n",
        "tab_settings = widgets.VBox([\n",
        "    widgets.HTML(\n",
        "        value=\"<h2>SD Interactive</h2>\",\n",
        "        layout=widgets.Layout(display=\"flex\", justify_content=\"center\")\n",
        "    ),\n",
        "    widgets.HTML(\n",
        "        value=\"<p>ðŸ”„</p>\",\n",
        "        layout=widgets.Layout(display=\"flex\", justify_content=\"center\")\n",
        "    ),\n",
        "])\n",
        "\n",
        "#\n",
        "tab.children = [\n",
        "  widgets.VBox(\n",
        "    #layout = {'height': '550px', 'max_height': '720px', 'margin':'8px'},\n",
        "    children = [\n",
        "        tab_sd,\n",
        "    ]),\n",
        "  widgets.VBox(\n",
        "    children = [\n",
        "        tab_settings,\n",
        "    ]),\n",
        "]\n",
        "\n",
        "tab_titles = [\"Stable Diffusion\", \"More Settings\"]\n",
        "tab.titles = tab_titles\n",
        "tab.selected_index = 0\n",
        "\n",
        "display(tab)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vRZQ4REGBHNP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "188e68e32864442f94aba8b50ded3655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6610798ec60426fac9695b71f48c180",
              "IPY_MODEL_16fe61ad77c04b1ab464b3bf643614c1"
            ],
            "layout": "IPY_MODEL_16f640c2a5564e53874b012b2c995e12"
          }
        },
        "d6610798ec60426fac9695b71f48c180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "GridBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "GridBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "GridBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25a28fce16db404183d3f5c8b622d347",
              "IPY_MODEL_b93b710d388a46bd83c548e639f36da1",
              "IPY_MODEL_2e5a3a64a9fe4015a9389e425c2d4609",
              "IPY_MODEL_bba242c9f51541f2a0157e1939875109"
            ],
            "layout": "IPY_MODEL_b35bbc0bd1f34e718a8a72704bf2ff61"
          }
        },
        "16fe61ad77c04b1ab464b3bf643614c1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6c0ede588db647098de1ba53691cd753",
            "msg_id": "",
            "outputs": []
          }
        },
        "16f640c2a5564e53874b012b2c995e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a28fce16db404183d3f5c8b622d347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f751af4de0420e838671f4e76c26f1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_aafc2d49df40407a81e6e5db6dae7226",
            "value": "<h2>Stable Diffusion Lite [Vorst Cavry]</h2>"
          }
        },
        "b93b710d388a46bd83c548e639f36da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b00f350e773e49708e64094b55e92604",
              "IPY_MODEL_cff722fd37dd4418bf1227f374670faf",
              "IPY_MODEL_a26f666c7b1c41858499a8082ef6f267",
              "IPY_MODEL_b365a794d7604af39beb93d91cb51d66",
              "IPY_MODEL_3e281c93a6ba4486afa7606eac910db5",
              "IPY_MODEL_1647fb539caf482db2503ed6c67c5d31",
              "IPY_MODEL_a4a98849a00345de8fc178326213309b",
              "IPY_MODEL_3fa5eaafcffc439d9ebb3df9a4e00c94",
              "IPY_MODEL_a1bdf7f95b22421f90f79023f9d95e0f",
              "IPY_MODEL_def7fc58d0774c92b7bdc6f5e83b8c8d",
              "IPY_MODEL_8e4e85c5ff444800a8f6d28e5b129e83",
              "IPY_MODEL_9a2ebfef87df4189ad7743c88a435358",
              "IPY_MODEL_de1fd2e2bc374dfc9ff1c159c7d7f9c0",
              "IPY_MODEL_ea149188c8b8457c8372f6a52b1bd636",
              "IPY_MODEL_4b885550478b45d2b8ff19ef9c3a7608"
            ],
            "layout": "IPY_MODEL_ee6f0fbedd9c4eb895c86c2d0033365f"
          }
        },
        "2e5a3a64a9fe4015a9389e425c2d4609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4d59d59d4864c48b9c685114adf5f7e",
              "IPY_MODEL_41197c527cd444ba848f36d08f1e7178",
              "IPY_MODEL_0007f640aadf4d058d54a355b392ce48",
              "IPY_MODEL_cd4a052e013e4a83b352450873350564",
              "IPY_MODEL_a347da3b170d4bcf9cf31d01b0621658",
              "IPY_MODEL_a0a5202e25054279b0e671236a042a04",
              "IPY_MODEL_48a9808182bb4f25b2c6e57cb97a8689",
              "IPY_MODEL_7c94b688652e41e99abbc41288e85283",
              "IPY_MODEL_4dd3a95f76244506bf8ca2043559e3c1",
              "IPY_MODEL_0ae94af0c2cc4984a7845759dcde8291",
              "IPY_MODEL_d22d45be453d405f851eb818db953712",
              "IPY_MODEL_dda18d9ae4cd443a99d94a1a37b0cc7a",
              "IPY_MODEL_396fb8fc02ef46e3aff49ae1f2023e64",
              "IPY_MODEL_be7cde45dbe04b6482df780828f90286"
            ],
            "layout": "IPY_MODEL_576242468ef14f329c43d852296ef5d2"
          }
        },
        "bba242c9f51541f2a0157e1939875109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f966c1d6ae3f4e568d445dd7bb812c7e",
              "IPY_MODEL_a57239bbc16c43b38b9cba57efde4fd0",
              "IPY_MODEL_3e7ce5da1f504feebcc320d34283a5b4"
            ],
            "layout": "IPY_MODEL_24f65b5e26cb4f9ebc441eb616141009"
          }
        },
        "b35bbc0bd1f34e718a8a72704bf2ff61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": "\"header header header\"\n\"left-sidebar center right-sidebar\"",
            "grid_template_columns": "1fr 2fr 1fr",
            "grid_template_rows": "1fr 3fr",
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f751af4de0420e838671f4e76c26f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": "header",
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aafc2d49df40407a81e6e5db6dae7226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b00f350e773e49708e64094b55e92604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "toonyou_beta6",
              "xxmix9realistic_v40",
              "animagine-xl"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Select Model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_dbcdbcfc0f5944caad2e87787350d4c6",
            "style": "IPY_MODEL_914bb332ef0c49b0849699486b3f9aaa"
          }
        },
        "cff722fd37dd4418bf1227f374670faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "None",
              "vae-ft-mse-840000-ema-pruned"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Select VAE:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_13c699f5c8fa4698977d3a666f4fc3ab",
            "style": "IPY_MODEL_67b24be8d61e46fcb18c2b77f3fe3982"
          }
        },
        "a26f666c7b1c41858499a8082ef6f267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Images:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6cd522def4db4b4b929d8a4aca56c200",
            "step": 1,
            "style": "IPY_MODEL_eddb672da7dd4ba7a784b68df78d19d4",
            "value": 5
          }
        },
        "b365a794d7604af39beb93d91cb51d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Steps:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f836965bce6245019a991111f014b05d",
            "step": 1,
            "style": "IPY_MODEL_326ab5386cb5487693e719502d886a58",
            "value": 30
          }
        },
        "3e281c93a6ba4486afa7606eac910db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatTextView",
            "continuous_update": false,
            "description": "CFG:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5af20017e1bf419f81007e778e28cf29",
            "step": null,
            "style": "IPY_MODEL_58b6e3b9d478499ea7ebc39077ed9a20",
            "value": 7.5
          }
        },
        "1647fb539caf482db2503ed6c67c5d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "DPM++ 2M",
              "DPM++ 2M Karras",
              "DPM++ 2M SDE",
              "DPM++ 2M SDE Karras",
              "DPM++ SDE",
              "DPM++ SDE Karras",
              "DPM2",
              "DPM2 Karras",
              "Euler",
              "Euler a",
              "Heun",
              "LMS",
              "LMS Karras",
              "DDIMScheduler"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Scheduler:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_134fbbd9c19e4846a3c4ffa5276e05d0",
            "style": "IPY_MODEL_c7206822a62c44fd9631998b8f387399"
          }
        },
        "a4a98849a00345de8fc178326213309b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Height:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_86c4fa5984f54720b295565b00d2f3a8",
            "step": 1,
            "style": "IPY_MODEL_d1f9e2eefde94f88b0adbee4fdcfa4b8",
            "value": 1080
          }
        },
        "3fa5eaafcffc439d9ebb3df9a4e00c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Width:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_70d4010a3ea14ba6acd2caf791b7e9c7",
            "step": 1,
            "style": "IPY_MODEL_b368b5ca7e2a410c9754082adc9eb060",
            "value": 512
          }
        },
        "a1bdf7f95b22421f90f79023f9d95e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Seed:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4be969c512af41a7884141fb40293b83",
            "step": 1,
            "style": "IPY_MODEL_b50f083edb6c42baa0ea65cee82e058d",
            "value": -1
          }
        },
        "def7fc58d0774c92b7bdc6f5e83b8c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "None",
              "masusu_breast",
              "GoodHands-beta2"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Lora1:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_aa9a4288ad1749cbaf0093b15d5283a7",
            "style": "IPY_MODEL_0c3e76bbdb434f6f8672b877e07e08af"
          }
        },
        "8e4e85c5ff444800a8f6d28e5b129e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatTextView",
            "continuous_update": false,
            "description": "Lora scale1:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9be8432c8cf54f95bab615ebe82fe3a7",
            "step": 0.01,
            "style": "IPY_MODEL_707e307fc1a44199a8b0bed1d0d10713",
            "value": 1
          }
        },
        "9a2ebfef87df4189ad7743c88a435358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "None",
              "masusu_breast",
              "GoodHands-beta2"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Lora2:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_ae27791def074e978489458c4cc1ec2b",
            "style": "IPY_MODEL_5302c29c33f24044a4efbeef4a746384"
          }
        },
        "de1fd2e2bc374dfc9ff1c159c7d7f9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatTextView",
            "continuous_update": false,
            "description": "Lora scale2:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8efdf65e994845bea105fd5104b92901",
            "step": 0.01,
            "style": "IPY_MODEL_522d4619aa4b40b089e44cfe600d1e87",
            "value": 1
          }
        },
        "ea149188c8b8457c8372f6a52b1bd636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "None",
              "masusu_breast",
              "GoodHands-beta2"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Lora3:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_745872c7d18041c6b34ff37ed4f4f852",
            "style": "IPY_MODEL_bff88e0e016945689fd959225f6db044"
          }
        },
        "4b885550478b45d2b8ff19ef9c3a7608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatTextView",
            "continuous_update": false,
            "description": "Lora scale3:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1b2f183c5a27418bbafec9dfc5496cb8",
            "step": 0.01,
            "style": "IPY_MODEL_8fda3c34d9f04b01a540aa1ff23d8b21",
            "value": 1
          }
        },
        "ee6f0fbedd9c4eb895c86c2d0033365f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": "left-sidebar",
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d59d59d4864c48b9c685114adf5f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Preprocess resolution ControlNet",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5ac5f579222f4181b51664978d0c9fab",
            "max": 2048,
            "min": 256,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_d984ecc032044784a4d484f2ed7f0331",
            "value": 512
          }
        },
        "41197c527cd444ba848f36d08f1e7178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "txt2img",
              "Openpose",
              "Canny",
              "MLSD",
              "scribble",
              "softedge",
              "segmentation",
              "depth",
              "NormalBae",
              "lineart",
              "shuffle",
              "ip2p"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "TASK:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_e624137f08c74151890b507e0e514a52",
            "style": "IPY_MODEL_796340036d07492383b478ff8ff9187d"
          }
        },
        "0007f640aadf4d058d54a355b392ce48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "None",
              "Openpose"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Preprocessor:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_c7bcacb250ca4cd081859e19593b426a",
            "style": "IPY_MODEL_4f8969a32ca44db8b9384538c982a710"
          }
        },
        "cd4a052e013e4a83b352450873350564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Canny low threshold:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c6696cf8f38249cdaf118c7ae692501b",
            "step": 1,
            "style": "IPY_MODEL_cc4ac58be35946c7ae9b29c32fd9123a",
            "value": 100
          }
        },
        "a347da3b170d4bcf9cf31d01b0621658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Canny high threshold:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0be365ae79fd461c83cbcaaf10e1a399",
            "step": 1,
            "style": "IPY_MODEL_3969d073066f438882e709660e046037",
            "value": 200
          }
        },
        "a0a5202e25054279b0e671236a042a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatTextView",
            "continuous_update": false,
            "description": "Hough value threshold (MLSD):",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9eef69a3ea604799b32ec1ffee9f58dd",
            "step": null,
            "style": "IPY_MODEL_77943f1ca6014e8989f4c13f4645fb72",
            "value": 0.1
          }
        },
        "48a9808182bb4f25b2c6e57cb97a8689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatTextView",
            "continuous_update": false,
            "description": "Hough distance threshold (MLSD):",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_916e8ca7fe5d454b9d0f04d98da9c203",
            "step": null,
            "style": "IPY_MODEL_f9515c5dffc7440a9f210c68e33ae16d",
            "value": 0.1
          }
        },
        "7c94b688652e41e99abbc41288e85283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "HED",
              "PidiNet",
              "None"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Preprocessor:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_9125952cc46943088eafbb14ae13f788",
            "style": "IPY_MODEL_f5b7d8f3b87e4991a00b4e789f524c28"
          }
        },
        "4dd3a95f76244506bf8ca2043559e3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "HED",
              "PidiNet",
              "HED safe",
              "PidiNet safe",
              "None"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Preprocessor:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_ca641550cf704a13b4cd2783dacda23c",
            "style": "IPY_MODEL_8d8fe5f89a0149c3a07747b88b3e0e7b"
          }
        },
        "0ae94af0c2cc4984a7845759dcde8291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "UPerNet",
              "None"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Preprocessor:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_965e9ce3d4684b05b7af64bc20b6cc14",
            "style": "IPY_MODEL_54ca212901b24621b8a6d87a7da3847f"
          }
        },
        "d22d45be453d405f851eb818db953712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Midas",
              "DPT",
              "None"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Preprocessor:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_8b997e3c5227473e9a8ad0afe7c5a12b",
            "style": "IPY_MODEL_2b529514bc974a1b9f0f8512bc42209b"
          }
        },
        "dda18d9ae4cd443a99d94a1a37b0cc7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "NormalBae",
              "None"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Preprocessor:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_1597f8cfb8a543e69fa13029263f8ca2",
            "style": "IPY_MODEL_0ba9838d682546df839bfdb07e231c8e"
          }
        },
        "396fb8fc02ef46e3aff49ae1f2023e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Lineart",
              "Lineart coarse",
              "None",
              "Lineart (anime)",
              "None (anime)"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Preprocessor:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_fb1a9c9f12854f0197f03bbeeb0cdd43",
            "style": "IPY_MODEL_461323b420f5460da913529f31c9e0f5"
          }
        },
        "be7cde45dbe04b6482df780828f90286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "ContentShuffle",
              "None"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Preprocessor:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_930e3ebf8d8e476297f14130ace761ca",
            "style": "IPY_MODEL_a4fa85f88f91415297f1deeaa857e875"
          }
        },
        "576242468ef14f329c43d852296ef5d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": "right-sidebar",
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f966c1d6ae3f4e568d445dd7bb812c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_73932b7f940643f7a03ea347efd26024",
            "placeholder": "Enter prompt",
            "rows": 5,
            "style": "IPY_MODEL_0e2c5bf2d1264c16a3621f50c976758d",
            "value": ""
          }
        },
        "a57239bbc16c43b38b9cba57efde4fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9fe5e811f1754c9ba8440600c453eac8",
            "placeholder": "Enter negative prompt",
            "rows": 5,
            "style": "IPY_MODEL_5720cfa0fa6e47b5a7aaaffacbfbaa4d",
            "value": ""
          }
        },
        "3e7ce5da1f504feebcc320d34283a5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Generate",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_429faec8806347a6945b73dca8761b68",
            "style": "IPY_MODEL_7a3b67c441ec4cb0aaa35728b2e6f681",
            "tooltip": ""
          }
        },
        "24f65b5e26cb4f9ebc441eb616141009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": "center",
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbcdbcfc0f5944caad2e87787350d4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "914bb332ef0c49b0849699486b3f9aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13c699f5c8fa4698977d3a666f4fc3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b24be8d61e46fcb18c2b77f3fe3982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cd522def4db4b4b929d8a4aca56c200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "eddb672da7dd4ba7a784b68df78d19d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f836965bce6245019a991111f014b05d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "326ab5386cb5487693e719502d886a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5af20017e1bf419f81007e778e28cf29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "58b6e3b9d478499ea7ebc39077ed9a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "134fbbd9c19e4846a3c4ffa5276e05d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "c7206822a62c44fd9631998b8f387399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "auto"
          }
        },
        "86c4fa5984f54720b295565b00d2f3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "d1f9e2eefde94f88b0adbee4fdcfa4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70d4010a3ea14ba6acd2caf791b7e9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "b368b5ca7e2a410c9754082adc9eb060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4be969c512af41a7884141fb40293b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "b50f083edb6c42baa0ea65cee82e058d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa9a4288ad1749cbaf0093b15d5283a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "0c3e76bbdb434f6f8672b877e07e08af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9be8432c8cf54f95bab615ebe82fe3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "707e307fc1a44199a8b0bed1d0d10713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae27791def074e978489458c4cc1ec2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "5302c29c33f24044a4efbeef4a746384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8efdf65e994845bea105fd5104b92901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "522d4619aa4b40b089e44cfe600d1e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "745872c7d18041c6b34ff37ed4f4f852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "bff88e0e016945689fd959225f6db044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b2f183c5a27418bbafec9dfc5496cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "8fda3c34d9f04b01a540aa1ff23d8b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ac5f579222f4181b51664978d0c9fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d984ecc032044784a4d484f2ed7f0331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "e624137f08c74151890b507e0e514a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796340036d07492383b478ff8ff9187d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7bcacb250ca4cd081859e19593b426a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "4f8969a32ca44db8b9384538c982a710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6696cf8f38249cdaf118c7ae692501b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "cc4ac58be35946c7ae9b29c32fd9123a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0be365ae79fd461c83cbcaaf10e1a399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3969d073066f438882e709660e046037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eef69a3ea604799b32ec1ffee9f58dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "77943f1ca6014e8989f4c13f4645fb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "916e8ca7fe5d454b9d0f04d98da9c203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "f9515c5dffc7440a9f210c68e33ae16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9125952cc46943088eafbb14ae13f788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "f5b7d8f3b87e4991a00b4e789f524c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca641550cf704a13b4cd2783dacda23c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8d8fe5f89a0149c3a07747b88b3e0e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "965e9ce3d4684b05b7af64bc20b6cc14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "54ca212901b24621b8a6d87a7da3847f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b997e3c5227473e9a8ad0afe7c5a12b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2b529514bc974a1b9f0f8512bc42209b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1597f8cfb8a543e69fa13029263f8ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0ba9838d682546df839bfdb07e231c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb1a9c9f12854f0197f03bbeeb0cdd43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "461323b420f5460da913529f31c9e0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "930e3ebf8d8e476297f14130ace761ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a4fa85f88f91415297f1deeaa857e875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73932b7f940643f7a03ea347efd26024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "600px"
          }
        },
        "0e2c5bf2d1264c16a3621f50c976758d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fe5e811f1754c9ba8440600c453eac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "600px"
          }
        },
        "5720cfa0fa6e47b5a7aaaffacbfbaa4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "429faec8806347a6945b73dca8761b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "7a3b67c441ec4cb0aaa35728b2e6f681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6c0ede588db647098de1ba53691cd753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}